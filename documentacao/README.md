# ü§ñ Projeto de Gera√ß√£o de Embeddings com IA para RAG

[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Maintainability](https://api.codeclimate.com/v1/badges/github/EliasAndrade/projeto-contagem-de-tokens/maintainability)](https://codeclimate.com/github/EliasAndrade/projeto-contagem-de-tokens/maintainability)
[![Test Coverage](https://api.codeclimate.com/v1/badges/github/EliasAndrade/projeto-contagem-de-tokens/test_coverage)](https://codeclimate.com/github/EliasAndrade/projeto-contagem-de-tokens/test_coverage)
[![GitHub Workflow Status](https://img.shields.io/github/workflow/status/EliasAndrade/projeto-contagem-de-tokens/CI)](https://github.com/EliasAndrade/projeto-contagem-de-tokens/actions)
[![Downloads](https://img.shields.io/github/downloads/EliasAndrade/projeto-contagem-de-tokens/total.svg)](https://github.com/EliasAndrade/projeto-contagem-de-tokens/releases)


## üìã √çndice
- [Sobre o Projeto](#sobre-o-projeto)
- [Funcionalidades](#funcionalidades)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Arquitetura](#arquitetura)
- [Instala√ß√£o](#instala√ß√£o)
- [Como Usar](#como-usar)
- [Configura√ß√£o](#configura√ß√£o)
- [M√©tricas e Monitoramento](#m√©tricas-e-monitoramento)
- [Solu√ß√£o de Problemas (Troubleshooting)](#solu√ß√£o-de-problemas-troubleshooting)
- [Perguntas Frequentes (FAQ)](#perguntas-frequentes-faq)
- [Contribui√ß√£o](#contribui√ß√£o)
- [Licen√ßa](#licen√ßa)
- [Scripts do Projeto](#scripts-do-projeto)


## üéØ Sobre o Projeto

Este projeto √© uma solu√ß√£o avan√ßada para gera√ß√£o de embeddings vetoriais utilizando Intelig√™ncia Artificial, especialmente projetado para alimentar sistemas RAG (Retrieval-Augmented Generation). O sistema processa documentos em YAML, gera embeddings utilizando modelos BERT e oferece uma interface rica para visualiza√ß√£o e an√°lise de m√©tricas em tempo real.  Ele foi desenvolvido com foco em efici√™ncia, escalabilidade e facilidade de uso, permitindo o processamento de grandes conjuntos de dados de forma eficiente.

### üåü Principais Caracter√≠sticas

- Gera√ß√£o de embeddings vetoriais de alta qualidade utilizando modelos pr√©-treinados de √∫ltima gera√ß√£o.
- Processamento em stream para grandes volumes de dados, permitindo o processamento de arquivos YAML de qualquer tamanho sem sobrecarregar a mem√≥ria.
- Integra√ß√£o com m√∫ltiplos modelos de IA (BERT, Sentence Transformers, e potencialmente outros modelos via APIs), oferecendo flexibilidade e adaptabilidade a diferentes necessidades.
- Interface rica com a biblioteca Rich, fornecendo uma experi√™ncia de usu√°rio intuitiva e informativa com m√©tricas em tempo real.
- Otimiza√ß√£o de recursos computacionais atrav√©s do uso de processamento paralelo (multithreading e multiprocessing), reduzindo o tempo de processamento.
- Cache inteligente de embeddings para evitar c√°lculos redundantes e acelerar o processamento subsequente.
- Suporte a processamento paralelo para maximizar o uso de recursos multi-core.
- Robustez e tratamento de erros para garantir a estabilidade do sistema.


## üõ† Funcionalidades

### Processamento de Dados
- **Convers√£o de documentos YAML para embeddings:** O sistema l√™ arquivos YAML contendo texto e gera embeddings vetoriais correspondentes.  Suporta diferentes estruturas de YAML, desde listas simples at√© estruturas complexas aninhadas.
- **Tokeniza√ß√£o avan√ßada com BERT:** Utiliza o modelo BERT para tokenizar o texto, considerando o contexto e a sem√¢ntica das palavras.  Isso garante uma representa√ß√£o vetorial mais precisa e significativa.
- **An√°lise sem√¢ntica com Sentence Transformers:** Emprega modelos Sentence Transformers para capturar a sem√¢ntica do texto, resultando em embeddings que refletem melhor o significado do conte√∫do.
- **Cache de embeddings para otimiza√ß√£o:** Armazena os embeddings gerados em cache para evitar c√°lculos repetidos, melhorando significativamente o desempenho, especialmente para grandes conjuntos de dados com textos repetidos ou similares.  O cache √© persistido em disco para uso em sess√µes subsequentes.

### M√©tricas e An√°lises
- **Contagem de tokens:** Fornece a contagem precisa de tokens para cada documento processado, permitindo o monitoramento do tamanho do texto e a otimiza√ß√£o do uso de recursos.
- **An√°lise de densidade sem√¢ntica:** Calcula a densidade sem√¢ntica dos embeddings, fornecendo insights sobre a riqueza e complexidade do conte√∫do.
- **Monitoramento de recursos (CPU, GPU, Mem√≥ria):** Monitora o uso de recursos do sistema em tempo real, permitindo a identifica√ß√£o de gargalos e a otimiza√ß√£o do desempenho.
- **Estat√≠sticas de processamento em tempo real:** Exibe estat√≠sticas de processamento, como tempo de processamento, taxa de processamento e progresso geral.

### Visualiza√ß√£o
- **Interface rica com Rich library:** Utiliza a biblioteca Rich para criar uma interface de linha de comando (CLI) interativa e visualmente atraente.
- **Pain√©is interativos:** Apresenta pain√©is interativos que permitem a navega√ß√£o e a an√°lise das m√©tricas.
- **Gr√°ficos de progresso:** Exibe gr√°ficos de progresso em tempo real, mostrando o andamento do processamento.
- **Indicadores de performance:** Fornece indicadores de performance chave (KPIs) para monitorar a efici√™ncia do sistema.


## üîß Tecnologias Utilizadas

- **Python 3.9+:** Linguagem de programa√ß√£o principal.
- **BERT (bert-base-uncased):** Modelo de linguagem pr√©-treinado para tokeniza√ß√£o e gera√ß√£o de embeddings.
- **Sentence Transformers:** Biblioteca para gerar embeddings sem√¢nticos de alta qualidade.
- **Google Gemini API (opcional):**  Integra√ß√£o opcional com a API do Google Gemini para gera√ß√£o de embeddings ainda mais avan√ßados. (Requer chave de API)
- **PyTorch:** Framework para processamento de dados e c√°lculos de embeddings.
- **NLTK:** Biblioteca para processamento de linguagem natural (NLP).
- **Rich:** Biblioteca para criar interfaces de usu√°rio ricas e interativas na linha de comando.
- **YAML:** Formato de dados utilizado para entrada e sa√≠da de documentos.
- **Asyncio:** Biblioteca para programa√ß√£o ass√≠ncrona, otimizando o processamento de dados.
- **Threading e Multiprocessing:** T√©cnicas de processamento paralelo para acelerar o processamento.
- **SQLite:** Banco de dados para armazenamento persistente de embeddings (opcional, para cache).


## üèó Arquitetura

O projeto utiliza uma arquitetura modular e escal√°vel, composta pelos seguintes componentes principais:

- **M√≥dulo de Pr√©-processamento:** Respons√°vel pela leitura e valida√ß√£o dos arquivos YAML, limpeza de dados e tokeniza√ß√£o do texto utilizando modelos BERT.
- **M√≥dulo de Gera√ß√£o de Embeddings:** Gera os embeddings vetoriais utilizando modelos Sentence Transformers, otimizado para processamento em stream e com cache inteligente para melhorar o desempenho.
- **M√≥dulo de Armazenamento:**  Utiliza um banco de dados SQLite para armazenar os embeddings gerados, permitindo acesso eficiente e persist√™ncia dos dados.
- **M√≥dulo de An√°lise:** Realiza an√°lises de m√©tricas, incluindo contagem de tokens, densidade sem√¢ntica e monitoramento de recursos do sistema.
- **M√≥dulo de Visualiza√ß√£o:**  Fornece uma interface de usu√°rio rica e interativa via CLI (usando a biblioteca Rich) para exibir as m√©tricas e resultados em tempo real.

Esta arquitetura modular permite f√°cil manuten√ß√£o, extens√£o e escalabilidade do sistema.  O design segue os princ√≠pios SOLID para garantir a manutenibilidade e a escalabilidade do c√≥digo.  O sistema √© projetado para lidar com grandes volumes de dados de forma eficiente, utilizando processamento paralelo e t√©cnicas de otimiza√ß√£o de mem√≥ria.


## ‚öôÔ∏è Instala√ß√£o

1. **Clone o reposit√≥rio:** `git clone https://github.com/EliasAndrade/projeto-contagem-de-tokens.git`
2. **Crie um ambiente virtual (recomendado):** `python3 -m venv .venv`
3. **Ative o ambiente virtual:** `.venv\Scripts\activate` (Windows)
4. **Instale as depend√™ncias:** `pip install -r requirements.txt`
5. **(Opcional) Configure a API Key do Google Gemini:**  Adicione sua chave de API no arquivo `config.yaml`.


## üé¨ Como Usar

1. **Prepare seus dados:** Organize seus dados em arquivos YAML, com cada arquivo contendo um ou mais documentos.
2. **Execute o script principal:** `python main.py --input_dir <caminho_para_seus_arquivos_yaml>`
3. **Monitore o progresso:** A interface Rich exibir√° o progresso do processamento, as m√©tricas e os resultados.
4. **Analise os resultados:** Os embeddings gerados ser√£o salvos em um banco de dados SQLite (ou em mem√≥ria, dependendo da configura√ß√£o).  Voc√™ pode acessar os embeddings e as m√©tricas atrav√©s da interface.


## ‚öôÔ∏è Configura√ß√£o

O arquivo `config.yaml` permite configurar diversos aspectos do projeto, incluindo:

- `input_dir`: Caminho para a pasta contendo os arquivos YAML de entrada.
- `output_dir`: Caminho para a pasta onde os resultados ser√£o salvos.
- `model_name`: Nome do modelo BERT a ser utilizado.
- `cache_size`: Tamanho m√°ximo do cache de embeddings (em MB).
- `num_workers`: N√∫mero de workers para processamento paralelo.
- `use_gemini_api`:  `true` ou `false` para habilitar/desabilitar a API do Google Gemini.
- `gemini_api_key`: Chave de API do Google Gemini (se `use_gemini_api` for `true`).


## üìä M√©tricas e Monitoramento

O sistema monitora e exibe as seguintes m√©tricas:

- **Tempo de processamento:** Tempo total gasto para processar todos os documentos.
- **Taxa de processamento:** N√∫mero de documentos processados por segundo.
- **Uso de CPU:** Porcentagem de uso da CPU durante o processamento.
- **Uso de RAM:** Quantidade de mem√≥ria RAM utilizada durante o processamento.
- **Tamanho do cache:** Tamanho atual do cache de embeddings.
- **N√∫mero de tokens:** Contagem total de tokens processados.
- **Densidade sem√¢ntica m√©dia:** Densidade sem√¢ntica m√©dia dos embeddings gerados.


## üêû Solu√ß√£o de Problemas (Troubleshooting)

- **Erro de importa√ß√£o de bibliotecas:** Certifique-se de ter instalado todas as depend√™ncias listadas em `requirements.txt`.
- **Erro de conex√£o com a API do Google Gemini:** Verifique sua chave de API e sua conex√£o com a internet.
- **Erro de processamento de arquivos YAML:** Certifique-se de que seus arquivos YAML est√£o bem formatados.
- **Uso excessivo de mem√≥ria:** Aumente o tamanho do cache ou reduza o n√∫mero de workers.


## ‚ùì Perguntas Frequentes (FAQ)

- **Qual o tamanho m√°ximo de arquivo YAML que o sistema suporta?**  O sistema suporta arquivos YAML de qualquer tamanho, gra√ßas ao processamento em stream.
- **Posso usar outros modelos de linguagem al√©m do BERT?**  Sim, o sistema pode ser adaptado para usar outros modelos, desde que sejam compat√≠veis com a biblioteca Sentence Transformers.
- **Como posso contribuir para o projeto?**  Veja a se√ß√£o "Contribui√ß√£o".


## ü§ù Contribui√ß√£o

Contribui√ß√µes s√£o bem-vindas!  Por favor, abra um pull request com suas altera√ß√µes.


## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT.

## üìú Scripts do Projeto

Esta se√ß√£o descreve os scripts Python principais do projeto:

### `automacao_organiza_projeto_restaura_backup_v1.py`

Este script automatiza o processo de backup, restaura√ß√£o e organiza√ß√£o dos arquivos do projeto. Ele utiliza a biblioteca `rich` para exibir mensagens formatadas no console e `logging` para registrar eventos.  As principais funcionalidades incluem:

- **Backup:** Cria um backup completo do projeto.
- **Restaura√ß√£o:** Restaura um backup anterior.
- **Organiza√ß√£o:** Organiza os arquivos em pastas espec√≠ficas por extens√£o (`.log`, `.txt`, `.json`, `.zip`).
- **Tratamento de Duplicatas:** Renomeia arquivos com nomes duplicados, adicionando um hash √∫nico ao nome.
- **Monitoramento:** Exibe o progresso e as estat√≠sticas da automa√ß√£o.

### `backup_projeto.py`

Este script cria um backup completo do projeto em um arquivo ZIP. Ele calcula o tamanho da pasta, gera um hash √∫nico para cada backup, obt√©m a √∫ltima vers√£o do backup e usa a biblioteca `rich` para criar um dashboard visual com as estat√≠sticas do backup.  Ele tamb√©m inclui tratamento de erros e logging.

### `banco_tokens.py`

Este script define fun√ß√µes para interagir com um banco de dados SQLite que armazena tokens e embeddings gerados pelo sistema.  As fun√ß√µes principais s√£o:

- `create_database()`: Cria o banco de dados SQLite se ele n√£o existir.
- `generate_unique_hash(input_text)`: Gera um hash SHA256 √∫nico para um dado texto.
- `analyze_bert(text, model_name="bert-base-uncased")`: Usa o modelo BERT para gerar tokens e embeddings para um dado texto.
- `insert_data(input_text, tokens, embeddings, db_name="tokens_database.db")`: Insere os dados (timestamp, hash √∫nico, texto, tokens e embeddings) no banco de dados.

### `contador_tokens_menu.py`

Este script fornece um menu interativo para analisar tokens e embeddings. Ele permite ao usu√°rio escolher entre v√°rias a√ß√µes, incluindo analisar vetores brutos, listar IDs aleat√≥rios ou espec√≠ficos, analisar indicadores estat√≠sticos, calcular a similaridade de cosseno entre vetores, exibir KPIs e sair.  Ele usa as bibliotecas `inquirer`, `colorama`, `matplotlib` e `scipy`.

### `gerador_yaml_embeddings_stream_v1.py`

Este script gera arquivos YAML usando a API do Google Gemini em modo de streaming. Ele inclui processamento de tokens BERT em threads separadas, monitoramento de recursos do sistema e um painel de estat√≠sticas em tempo real usando a biblioteca `rich`.  Ele tamb√©m calcula m√©tricas avan√ßadas, como densidade sem√¢ntica e diversidade lexical.  As principais caracter√≠sticas incluem:

- **Gera√ß√£o de YAML em Streaming:** Gera arquivos YAML usando a API do Google Gemini com streaming para lidar com grandes quantidades de texto.
- **Processamento de Tokens BERT Multi-threaded:** Utiliza o modelo BERT para tokenizar o texto em paralelo, melhorando o desempenho.
- **Monitoramento de Recursos:** Monitora o uso de CPU, mem√≥ria e GPU (se dispon√≠vel) em tempo real.
- **Painel de Estat√≠sticas:** Exibe um painel interativo com estat√≠sticas de processamento, incluindo contagem de tokens, palavras, tempo de processamento, uso de recursos e outras m√©tricas.
- **M√©tricas Avan√ßadas:** Calcula m√©tricas como densidade sem√¢ntica, diversidade lexical e outras m√©tricas relevantes para an√°lise de texto.

### `gerador_yaml_embeddings-prompt-v2.py`

Este script gera arquivos YAML contendo listas de palavras para embeddings, usando a API do Google Gemini. Ele permite configurar a gera√ß√£o (temperatura, top_p, etc.) e inclui um prompt de sistema para garantir a qualidade e diversidade do texto gerado.

### `gerador_yaml_embeddings.py`

Este script gera arquivos YAML com configura√ß√µes para embeddings de texto, usando a API do Google Gemini. Ele permite ao usu√°rio especificar um tema e o n√∫mero de itera√ß√µes, gerando arquivos YAML com diferentes configura√ß√µes.

### `gerador-dic-texto-yaml-v1.py`

Este script gera um arquivo de texto contendo um e-book estruturado em cap√≠tulos, usando a API do Google Gemini. O usu√°rio fornece o nome do e-book e o tema, e o script gera os t√≥picos e o conte√∫do de cada cap√≠tulo.

### `limpar_duplicados_avancado.py`

Este script realiza uma limpeza avan√ßada de duplicados, comparando arquivos com base em seus hashes SHA256. Ele remove duplicados internos em uma pasta de backup e arquivos do backup que j√° existem na pasta raiz.  Ele tamb√©m remove pastas vazias.
