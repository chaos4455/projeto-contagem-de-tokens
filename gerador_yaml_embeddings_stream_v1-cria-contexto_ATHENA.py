import yaml
import hashlib
from datetime import datetime, timedelta
import google.generativeai as genai
import os
from pathlib import Path
import time
from colorama import init, Fore, Style, Back
from rich.console import Console
from rich.panel import Panel
from rich.live import Live
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.layout import Layout
from rich.columns import Columns
from rich.align import Align
from collections import Counter, deque
from rich.style import Style
from rich.text import Text
from rich.padding import Padding
import nltk
from nltk.tokenize import word_tokenize
import statistics
import asyncio
from transformers import BertTokenizer, BertModel
import torch
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Dict, List
import psutil
import GPUtil
from rich.console import Console
from rich.panel import Panel
from rich.live import Live
from rich.table import Table
from rich.layout import Layout
from rich.align import Align
from rich.text import Text
from rich.box import ROUNDED, HEAVY, SIMPLE  # Importa√ß√£o correta dos boxes
from psutil import cpu_percent, virtual_memory, disk_usage
import platform
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
from threading import Thread
import multiprocessing
from functools import partial
from dataclasses import dataclass
from collections import defaultdict
import aiofiles
from contextlib import suppress

# Download necess√°rio do NLTK
nltk.download('punkt', quiet=True)

# Inicializa√ß√£o
init(autoreset=True)
console = Console()

# Emojis e √≠cones
EMOJI = {
    "stream": "üåä",
    "token": "üéØ",
    "palavra": "üìù",
    "letra": "üìä",
    "tempo": "‚è±Ô∏è",
    "arquivo": "üóÇ",
    "stats": "üìà",
    "max": "‚¨ÜÔ∏è",
    "min": "‚¨áÔ∏è",
    "media": "‚û°Ô∏è",
    "total": "üíØ",
    "velocidade": "üöÄ",
    "memoria": "üíæ",
    "processando": "‚ö°"
}

# üîë Configura√ß√£o da API
API_KEY = "AIzaSyCEagEEnX-RdkW3-jCAb0H9nrTsgcE-Qqo"
genai.configure(api_key=API_KEY)

# üéØ Configura√ß√µes do modelo
NOME_MODELO = "gemini-1.5-flash"
CONFIG_GERACAO = {
    "temperature": 0.8,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8096,
}

# Configura√ß√µes Globais
TOKEN_COUNTER = True  # Define se a an√°lise de tokens BERT ser√° realizada (True/False)

@dataclass
class TokenBatch:
    """Estrutura para batch de tokens"""
    text: str
    timestamp: float
    batch_id: int

class AdvancedMetrics:
    def __init__(self):
        try:
            self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            console.print(f"[yellow]Aviso: Usando fallback para tokeniza√ß√£o: {str(e)}[/yellow]")
            self.bert_tokenizer = None
            self.sentence_model = None
            
        self.embedding_dim = 384
        self.embedding_cache = {}
        self.token_frequency = {}
        self.sentence_lengths = []
        self.embedding_magnitudes = []
        self.token_diversity = 0.0
        self.semantic_density = 0.0
        self.cpu_usage = 0.0
        self.memory_usage = 0.0
        self.gpu_usage = 0.0

class SystemMonitor:
    """Monitora recursos do sistema com fallbacks"""
    def __init__(self):
        self.os_type = platform.system()
        self.fallback_mode = False
        
        # Tenta inicializar contadores
        try:
            self.cpu_percent = psutil.cpu_percent(interval=0.1)
            self.cpu_per_core = psutil.cpu_percent(percpu=True)
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è Usando modo fallback para m√©tricas de CPU[/yellow]")
            self.fallback_mode = True

    def get_cpu_stats(self):
        """Obt√©m estat√≠sticas de CPU com fallback"""
        try:
            if self.fallback_mode:
                # Fallback usando /proc no Linux ou wmic no Windows
                if self.os_type == "Linux":
                    with open('/proc/stat', 'r') as f:
                        cpu_lines = f.readlines()
                    return {
                        'total': float(cpu_lines[0].split()[1]),
                        'cores': [float(line.split()[1]) for line in cpu_lines[1:] if line.startswith('cpu')]
                    }
                else:
                    # Windows fallback
                    return {
                        'total': os.getloadavg()[0] if hasattr(os, 'getloadavg') else 0,
                        'cores': [0] * psutil.cpu_count()
                    }
            else:
                return {
                    'total': psutil.cpu_percent(interval=0.1),
                    'cores': psutil.cpu_percent(percpu=True)
                }
        except Exception:
            return {'total': 0, 'cores': [0] * psutil.cpu_count()}

    def get_memory_stats(self):
        """Obt√©m estat√≠sticas de mem√≥ria com fallback"""
        try:
            mem = psutil.virtual_memory()
            swap = psutil.swap_memory()
            return {
                'used': mem.used,
                'total': mem.total,
                'percent': mem.percent,
                'swap_percent': swap.percent
            }
        except Exception:
            return {
                'used': 0,
                'total': 0,
                'percent': 0,
                'swap_percent': 0
            }

class StreamStats:
    def __init__(self):
        self.metrics = AdvancedMetrics()
        # Contadores b√°sicos
        self.caracteres = 0
        self.palavras = 0
        self.tokens_bert = 0
        self.palavras_unicas = set()
        self.token_unicos = set()
        self.maiores_palavras = []
        self.ultimas_palavras = deque(maxlen=10)
        self.inicio = time.time()
        self.chars_por_segundo = 0
        self.palavras_por_segundo = 0
        self.tokens_por_segundo = 0
        self.buffer = ""
        
        # Controle de itera√ß√£o
        self.iteracao_atual = 0
        self.total_iteracoes = 20
        self.ultimo_arquivo = ""
        
        # M√©tricas calculadas
        self.media_tamanho_palavras = 0
        self.diversidade_lexica = 0
        self.token_ratio = 0
        
        # Inicializa m√©tricas do sistema
        self.atualizar_metricas_sistema()

        # Inicializa√ß√£o condicional do tokenizador BERT
        self.bert_enabled = TOKEN_COUNTER
        if self.bert_enabled:
            try:
                console.print("[cyan]üéØ Token Counter: ATIVADO - Iniciando BERT...[/cyan]")
                self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
                self.tokens_bert = 0
                self.token_unicos = set()
                self.token_frequency = {}
                self.tokens_por_segundo = 0
                self.token_stats = {
                    'media_len': 0,
                    'max_len': 0,
                    'subwords_ratio': 0,
                    'special_tokens': 0
                }
                console.print("[green]‚úÖ BERT inicializado com sucesso![/green]")
            except Exception as e:
                console.print(f"[yellow]‚ö†Ô∏è Aviso: Erro ao inicializar BERT: {e}[/yellow]")
                self.bert_tokenizer = None
        else:
            console.print("[yellow]‚ö†Ô∏è Token Counter: DESATIVADO - BERT n√£o ser√° utilizado[/yellow]")
            self.bert_tokenizer = None

        self.system_monitor = SystemMonitor()

        # Adicionar atributos faltantes
        self.sentences = []
        self.embedding_stats = {
            'min_magnitude': 0,
            'max_magnitude': 0,
            'avg_magnitude': 0
        }
        self.top_tokens = []  # Lista para os tokens mais frequentes
        self.eficiencia_tokens = 0.0
        self.cobertura_vocab = 0.0
        self.densidade_texto = 0.0
        self.performance_score = 0.0

    def safe_div(self, n, d):
        """Divis√£o segura com valor default 0"""
        try:
            if d == 0:
                return 0.0
            result = float(n) / float(d)
            return result if result != float('inf') else 0.0
        except:
            return 0.0

    def safe_mean(self, values):
        """M√©dia segura com verifica√ß√µes"""
        try:
            cleaned_values = [float(v) for v in values if v is not None and str(v).strip()]
            return np.mean(cleaned_values) if cleaned_values else 0.0
        except:
            return 0.0

    async def atualizar(self, novo_texto: str, iteracao: int = 0, arquivo: str = ""):
        """Atualiza estat√≠sticas com novo texto"""
        try:
            if not novo_texto:
                return
                
            # Atualiza controle de itera√ß√£o
            self.iteracao_atual = iteracao
            if arquivo:
                self.ultimo_arquivo = Path(arquivo).name
            
            # Atualiza contadores b√°sicos
            self.buffer += novo_texto
            self.caracteres += len(novo_texto)
            
            # Processa palavras
            palavras = word_tokenize(novo_texto)
            self.palavras += len(palavras)
            
            for palavra in palavras:
                if palavra.strip():
                    self.palavras_unicas.add(palavra)
                    self.ultimas_palavras.append(palavra)
                    
                    # Atualiza maiores palavras
                    if not palavra in [p[1] for p in self.maiores_palavras]:
                        self.maiores_palavras.append((len(palavra), palavra))
                        self.maiores_palavras.sort(reverse=True)
                        self.maiores_palavras = self.maiores_palavras[:10]
            
            # Atualiza m√©tricas calculadas
            tempo_total = max(0.001, time.time() - self.inicio)
            self.chars_por_segundo = self.caracteres / tempo_total
            self.palavras_por_segundo = self.palavras / tempo_total
            self.tokens_por_segundo = self.tokens_bert / tempo_total
            
            # Calcula m√©dias e ratios
            if self.palavras > 0:
                tamanhos = [len(p) for p in self.palavras_unicas]
                self.media_tamanho_palavras = sum(tamanhos) / len(tamanhos) if tamanhos else 0
                self.diversidade_lexica = len(self.palavras_unicas) / self.palavras
                
            if self.tokens_bert > 0:
                self.token_ratio = len(self.token_unicos) / self.tokens_bert
            
            # Atualiza m√©tricas do sistema
            self.atualizar_metricas_sistema()
            
            # Processamento BERT ass√≠ncrono
            await self.processar_tokens_bert(novo_texto)
            
        except Exception as e:
            console.print(f"[yellow]Erro ao atualizar estat√≠sticas: {e}[/yellow]")

    async def processar_tokens_bert(self, texto: str):
        """Processa tokens BERT de forma s√≠ncrona"""
        if not TOKEN_COUNTER or not self.bert_tokenizer:
            return
            
        try:
            tokens = self.bert_tokenizer.tokenize(texto)
            stats = {
                'num_tokens': len(tokens),
                'unique_tokens': len(set(tokens)),
                'subwords': sum(1 for t in tokens if t.startswith('##')),
                'special': sum(1 for t in tokens if t in self.bert_tokenizer.special_tokens_map.values()),
                'max_len': max(len(t) for t in tokens) if tokens else 0,
                'avg_len': np.mean([len(t) for t in tokens]) if tokens else 0
            }
            
            self.atualizar_estatisticas_bert(stats)
            
        except Exception as e:
            console.print(f"[yellow]Erro ao processar tokens BERT: {e}[/yellow]")

    def atualizar_estatisticas_bert(self, stats: Dict):
        """Atualiza estat√≠sticas do BERT"""
        try:
            self.tokens_bert += stats['num_tokens']
            self.token_stats['media_len'] = stats['avg_len']
            self.token_stats['max_len'] = max(self.token_stats['max_len'], stats['max_len'])
            self.token_stats['subwords_ratio'] = stats['subwords'] / max(1, stats['num_tokens'])
            self.token_stats['special_tokens'] += stats['special']
            
            # Atualiza taxa de processamento
            tempo_total = max(0.001, time.time() - self.inicio)
            self.tokens_por_segundo = self.tokens_bert / tempo_total
            
        except Exception as e:
            console.print(f"[yellow]Erro ao atualizar estat√≠sticas BERT: {e}[/yellow]")

    def calcular_metricas_avancadas(self, texto: str):
        try:
            if not texto.strip():
                return
                
            # Tokeniza√ß√£o segura
            if self.metrics.bert_tokenizer:
                tokens_bert = self.metrics.bert_tokenizer.tokenize(texto)
                self.tokens_bert = max(1, self.tokens_bert + len(tokens_bert))
            
            # An√°lise de senten√ßas
            sentences = nltk.sent_tokenize(texto)
            if sentences:
                self.sentences.extend(sentences)
            
            # Embeddings seguros
            if self.metrics.sentence_model and texto.strip():
                try:
                    embedding = self.metrics.sentence_model.encode(texto)
                    magnitude = float(np.linalg.norm(embedding))
                    
                    if not np.isnan(magnitude) and magnitude > 0:
                        self.metrics.embedding_magnitudes.append(magnitude)
                        
                        # Atualizar estat√≠sticas
                        mags = [m for m in self.metrics.embedding_magnitudes if m > 0]
                        if mags:
                            self.embedding_stats['min_magnitude'] = min(mags)
                            self.embedding_stats['max_magnitude'] = max(mags)
                            self.embedding_stats['avg_magnitude'] = self.safe_mean(mags)
                except:
                    pass
            
            # M√©tricas de sistema
            try:
                self.metrics.cpu_usage = psutil.cpu_percent()
                self.metrics.memory_usage = psutil.virtual_memory().percent
                if len(GPUtil.getGPUs()) > 0:
                    self.metrics.gpu_usage = GPUtil.getGPUs()[0].load * 100
            except:
                pass
                
        except Exception as e:
            console.print(f"[yellow]Aviso em m√©tricas avan√ßadas: {str(e)}[/yellow]")

    def atualizar_metricas_sistema(self):
        """Atualiza m√©tricas do sistema"""
        try:
            self.cpu_total = psutil.cpu_percent()
            self.cpu_cores = psutil.cpu_percent(percpu=True)
            self.ram = psutil.virtual_memory()
            self.disk = psutil.disk_usage('/')
        except Exception as e:
            console.print(f"[yellow]Erro ao atualizar m√©tricas do sistema: {e}[/yellow]")

    def formatar_tempo(self, segundos):
        """Formata segundos em HH:MM:SS"""
        horas = int(segundos // 3600)
        minutos = int((segundos % 3600) // 60)
        segs = int(segundos % 60)
        return f"{horas:02d}:{minutos:02d}:{segs:02d}"

    def criar_grid_layout(self):
        try:
            tempo_atual = time.time()
            tempo_total = max(0.001, tempo_atual - self.inicio)
            tempo_formatado = str(timedelta(seconds=int(tempo_total)))

            layout = Layout()
            layout.split_column(
                Layout(name="header", size=3),
                Layout(name="main", size=30),
                Layout(name="footer", size=3)
            )

            # Header com m√©tricas de processamento
            header = Panel(
                Align.center(
                    Text.assemble(
                        (f"üöÄ BERT Processor ", "bold cyan"),
                        (f"| ‚è±Ô∏è {tempo_formatado}", "magenta")
                    )
                ),
                border_style="blue",
                box=ROUNDED
            )
            layout["header"].update(header)

            # 6 colunas para m√©tricas
            layout["main"].split_row(
                Layout(name="system", ratio=1),
                Layout(name="process", ratio=1),
                Layout(name="tokens", ratio=1),
                Layout(name="words", ratio=1),
                Layout(name="stats", ratio=1),
                Layout(name="tops", ratio=1)
            )

            # 1. Sistema e Recursos
            system_stats = self.system_monitor.get_cpu_stats()
            memory_stats = self.system_monitor.get_memory_stats()
            
            system_table = Table(box=ROUNDED, expand=True)
            system_table.add_column("üíª Sistema", style="cyan")
            system_table.add_column("Valor", justify="right", style="green")
            
            # CPU com fallback
            system_table.add_row("üñ•Ô∏è CPU Total", f"{system_stats['total']:.1f}%")
            for i, cpu in enumerate(system_stats['cores']):
                with suppress(Exception):
                    system_table.add_row(f"Core {i+1}", f"{cpu:.1f}%")
            
            # Mem√≥ria com fallback
            system_table.add_row("üß† RAM Uso", f"{memory_stats['percent']}%")
            system_table.add_row("üíæ RAM Total", f"{memory_stats['total']/1024**3:.1f}GB")
            system_table.add_row("üìä RAM Livre", f"{(memory_stats['total']-memory_stats['used'])/1024**3:.1f}GB")
            
            if memory_stats['swap_percent'] > 0:
                system_table.add_row("üí´ Swap", f"{memory_stats['swap_percent']}%")
            
            # Informa√ß√µes do sistema
            system_table.add_row("üîß Sistema", platform.system())
            system_table.add_row("üìå Python", platform.python_version())
            
            if self.system_monitor.fallback_mode:
                system_table.add_row("‚ö†Ô∏è Modo", "Fallback", style="yellow")
            
            layout["system"].update(Panel(
                system_table,
                title="üíª Sistema" + (" (Fallback)" if self.system_monitor.fallback_mode else ""),
                border_style="blue"
            ))

            # 2. Processamento
            process_table = Table(box=ROUNDED, expand=True)
            process_table.add_column("‚ö° Processo", style="magenta")
            process_table.add_column("Valor", justify="right", style="yellow")
            
            process_table.add_row("üìù Itera√ß√£o", f"{self.iteracao_atual}/{self.total_iteracoes}")
            process_table.add_row("‚è±Ô∏è Tempo", tempo_formatado)
            process_table.add_row("üìä Chars/s", f"{self.chars_por_segundo:.1f}")
            process_table.add_row("üöÄ Words/s", f"{self.palavras_por_segundo:.1f}")
            process_table.add_row("üíæ Buffer", f"{len(self.buffer):,}")
            process_table.add_row("üìà Total KB", f"{self.caracteres/1024:.1f}")
            
            layout["process"].update(Panel(process_table, title="‚ö° Processamento", border_style="magenta"))

            # 3. Tokens BERT
            tokens_table = Table(box=ROUNDED, expand=True)
            tokens_table.add_column("üéØ Tokens", style="blue")
            tokens_table.add_column("Valor", justify="right", style="cyan")
            
            tokens_table.add_row("üìä Total", f"{self.tokens_bert:,}")
            tokens_table.add_row("üîÑ Por Seg", f"{self.tokens_por_segundo:.1f}")
            tokens_table.add_row("üìà √önicos", f"{len(self.token_unicos):,}")
            tokens_table.add_row("üéØ Ratio", f"{self.token_stats['subwords_ratio']:.1%}")
            tokens_table.add_row("üìè M√©dia Len", f"{self.token_stats['media_len']:.1f}")
            tokens_table.add_row("‚ö° Especiais", f"{self.token_stats['special_tokens']}")
            
            # Top 5 tokens mais frequentes
            tokens_table.add_row("üìà TOP TOKENS", "", style="bold magenta")
            for token, freq in self.top_tokens[:5]:
                tokens_table.add_row("üî§", f"{token} ({freq})")
            
            layout["tokens"].update(Panel(tokens_table, title="üéØ Tokens BERT", border_style="cyan"))

            # 4. An√°lise de Palavras
            words_table = Table(box=ROUNDED, expand=True)
            words_table.add_column("üìù Palavras", style="yellow")
            words_table.add_column("Valor", justify="right", style="green")
            
            words_table.add_row("üìö Total", f"{self.palavras:,}")
            words_table.add_row("üéØ √önicas", f"{len(self.palavras_unicas):,}")
            words_table.add_row("üìä M√©dia Len", f"{self.media_tamanho_palavras:.1f}")
            words_table.add_row("üí´ Diversidade", f"{self.diversidade_lexica:.1%}")
            
            # √öltimas 10 palavras
            words_table.add_row("ÔøΩÔøΩÔøΩ √öLTIMAS", "", style="bold cyan")
            for palavra in list(self.ultimas_palavras)[-10:]:
                words_table.add_row("üìñ", palavra)
            
            layout["words"].update(Panel(words_table, title="üìù An√°lise", border_style="yellow"))

            # 5. Estat√≠sticas
            stats_table = Table(box=ROUNDED, expand=True)
            stats_table.add_column("üìä Stats", style="red")
            stats_table.add_column("Valor", justify="right", style="blue")
            
            stats_table.add_row("üéØ Efici√™ncia", f"{self.eficiencia_tokens:.1%}")
            stats_table.add_row("üìà Cobertura", f"{self.cobertura_vocab:.1%}")
            stats_table.add_row("üí´ Densidade", f"{self.densidade_texto:.2f}")
            stats_table.add_row("‚ö° Performance", f"{self.performance_score:.1f}")
            
            layout["stats"].update(Panel(stats_table, title="üìä Estat√≠sticas", border_style="red"))

            # 6. Tops e Rankings
            tops_table = Table(box=ROUNDED, expand=True)
            tops_table.add_column("üèÜ Tops", style="green")
            tops_table.add_column("Valor", justify="right", style="magenta")
            
            # Top 10 maiores palavras
            tops_table.add_row("üìè MAIORES", "", style="bold yellow")
            for tamanho, palavra in sorted(self.maiores_palavras, reverse=True)[:10]:
                tops_table.add_row("üìè", f"{palavra} ({tamanho})")
            
            layout["tops"].update(Panel(tops_table, title="üèÜ Rankings", border_style="green"))

            return layout

        except Exception as e:
            console.print(f"[yellow]Aviso no layout: {str(e)}[/yellow]")
            return Layout()

class StreamProcessor:
    def __init__(self):
        self.console = Console()
        self.stats = StreamStats()
        self.live = Live(
            self.stats.criar_grid_layout(),
            console=self.console,
            auto_refresh=True,
            refresh_per_second=10,
            screen=True
        )

    async def processar_yaml(self, prompt: str, arquivo_yaml: Path, iteracao: int, total: int):
        """Processa um √∫nico YAML com atualiza√ß√µes em tempo real"""
        try:
            self.stats.iteracao_atual = iteracao
            self.stats.total_iteracoes = total
            
            # Inicializa o modelo
            model = genai.GenerativeModel(
                model_name=NOME_MODELO,
                generation_config=CONFIG_GERACAO
            )

            # Processa o stream
            response = model.generate_content(prompt, stream=True)
            
            # Abre o arquivo em modo append para escrita em tempo real
            async with aiofiles.open(arquivo_yaml, 'a', encoding='utf-8') as f:
                buffer = ""
                for chunk in response:
                    if chunk.text:
                        texto = chunk.text
                        buffer += texto
                        
                        # Escreve imediatamente no arquivo
                        await f.write(texto)
                        await f.flush()  # For√ßa a escrita no disco
                        
                        # Atualiza estat√≠sticas
                        await self.stats.atualizar(texto, iteracao, arquivo_yaml.name)
                        
                        # Atualiza display em tempo real
                        self.live.update(self.stats.criar_grid_layout())
                        
                        # Pequena pausa para n√£o sobrecarregar o display
                        await asyncio.sleep(0.01)
                
                # Processa m√©tricas finais do texto completo
                self.stats.calcular_metricas_avancadas(buffer)
                self.live.update(self.stats.criar_grid_layout())
            
            return True

        except Exception as e:
            self.console.print(f"[red]Erro ao processar YAML {iteracao}: {str(e)}[/red]")
            return False

    async def processar_iteracoes(self, palavra_inicial: str):
        """Processa todas as itera√ß√µes sequencialmente"""
        total_iteracoes = 20
        
        with self.live:
            self.console.clear()
            
            for i in range(total_iteracoes):
                try:
                    # Prepara diret√≥rio e arquivo
                    output_dir = Path("generated-yaml-text-to-embedding")
                    output_dir.mkdir(exist_ok=True)
                    
                    # Gera nome √∫nico para o arquivo
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    hash_id = hashlib.md5(f"{timestamp}_{i}".encode()).hexdigest()[:8]
                    arquivo_yaml = output_dir / f"embedding_stream_v1_{hash_id}.yaml"
                    
                    # Template do prompt
                    prompt = f"""
                    Baseado na palavra-chave '{palavra_inicial}', gere um YAML t√©cnico e detalhado.
                    Itera√ß√£o: {i+1}/{total_iteracoes}
                    
                    Requisitos:
                    - Estrutura YAML v√°lida
                    - Conte√∫do t√©cnico relacionado √† palavra-chave
                    - M√≠nimo de 3 n√≠veis de profundidade
                    - Incluir exemplos pr√°ticos
                    """
                    
                    # Processa um YAML por vez
                    console.print(f"\n[cyan]Processando YAML {i+1}/{total_iteracoes}...[/cyan]")
                    await self.processar_yaml(prompt, arquivo_yaml, i+1, total_iteracoes)
                    
                    # Pequena pausa entre arquivos
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    self.console.print(f"[red]Erro na itera√ß√£o {i+1}: {str(e)}[/red]")

async def main():
    try:
        processor = StreamProcessor()
        
        console.print(f"\n{EMOJI['palavra']} [cyan]Digite a palavra inicial:[/cyan]")
        palavra_inicial = input().strip()
        
        if not palavra_inicial:
            console.print("[red]Palavra inicial n√£o pode estar vazia![/red]")
            return
        
        console.clear()
        await processor.processar_iteracoes(palavra_inicial)
        
        console.print(Panel(
            f"[green]üéâ Processo completo![/green]\n"
            f"YAMLs gerados com sucesso na pasta 'generated-yaml-text-to-embedding'",
            border_style="green"
        ))
        
    except KeyboardInterrupt:
        console.print("\n[yellow]Opera√ß√£o cancelada pelo usu√°rio.[/yellow]")
    except Exception as e:
        console.print(f"[red]Erro durante o processamento: {str(e)}[/red]")

if __name__ == "__main__":
    asyncio.run(main())

# ----ATHENA----
