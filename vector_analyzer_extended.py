from transformers import BertTokenizer, BertModel
import torch
import numpy as np
from rich.console import Console
from rich.layout import Layout
from rich.panel import Panel
from rich.table import Table
from rich.progress import track
from rich.live import Live
from rich import box
from rich.markdown import Markdown
from rich.syntax import Syntax
from rich.align import Align
import numpy as np
from colorama import init, Fore, Back, Style
from sklearn.preprocessing import MinMaxScaler
import math
from datetime import datetime
import psutil
import platform
import requests
import json
from rich.tree import Tree
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn
import socket
import sys
import time
import random
import sqlite3

# Inicializa√ß√£o
init()  # Colorama
console = Console()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Configura√ß√µes da API
API_CONFIG = {
    "host": "localhost",
    "port": 8000,
    "base_url": "http://localhost:8000",
    "endpoint": "/vectors/"
}

# Carregar modelo BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)

def get_system_info():
    """Obt√©m informa√ß√µes do sistema"""
    return {
        "os": platform.system(),
        "python_version": platform.python_version(),
        "cpu_usage": psutil.cpu_percent(),
        "memory_usage": psutil.virtual_memory().percent,
        "hostname": socket.gethostname(),
        "ip": socket.gethostbyname(socket.gethostname())
    }

def get_api_health():
    """Verifica a sa√∫de da API"""
    try:
        response = requests.get(f"{API_CONFIG['base_url']}/docs")
        return response.status_code == 200
    except:
        return False

def decode_vector_to_words(vector_values):
    """Converte vetor em palavras usando BERT"""
    try:
        # Normaliza√ß√£o do vetor
        scaler = MinMaxScaler()
        normalized_vector = scaler.fit_transform(np.array(vector_values).reshape(-1, 1)).flatten()
        
        # Converte para tensor e processa com BERT
        with torch.no_grad():
            inputs = torch.tensor(normalized_vector).unsqueeze(0).to(device)
            outputs = model(inputs)
            predictions = outputs[0]
        
        # Pega os tokens mais prov√°veis
        token_ids = torch.argmax(predictions, dim=-1)
        tokens = tokenizer.convert_ids_to_tokens(token_ids[0])
        
        # Remove tokens especiais e junta as palavras
        words = []
        for token in tokens:
            if token not in ['[PAD]', '[CLS]', '[SEP]', '[UNK]']:
                # Remove ## dos subtokens do BERT
                if token.startswith('##'):
                    if words:
                        words[-1] = words[-1] + token[2:]
                else:
                    words.append(token)
        
        return ' '.join(words)
    except Exception as e:
        console.print(f"[red]Erro ao decodificar vetor: {str(e)}[/]")
        return "N/A"

def analyze_vector(vector_id, vector_values, word=None, palavra_origem=None):
    """Analisa um vetor e retorna estat√≠sticas detalhadas"""
    
    # Header com informa√ß√µes do sistema
    sys_info = get_system_info()
    console.print(Panel.fit(
        f"üñ•Ô∏è Sistema: {sys_info['os']} | üêç Python: {sys_info['python_version']} | "
        f"üìä CPU: {sys_info['cpu_usage']}% | üíæ RAM: {sys_info['memory_usage']}%",
        title="[bold cyan]Status do Sistema[/]",
        subtitle="üîß Informa√ß√µes T√©cnicas"
    ))

    # Informa√ß√µes da Palavra
    decoded_word = decode_vector_to_words(vector_values)
    console.print(Panel.fit(
        f"üìù Palavra Original: [bold green]{word}[/]\n"
        f"üîÑ Palavra Decodificada: [bold yellow]{decoded_word}[/]\n"
        f"üåç Origem: [bold blue]{palavra_origem or 'N/A'}[/]\n"
        f"üî¢ ID: [bold cyan]{vector_id}[/]",
        title="[bold magenta]Informa√ß√µes da Palavra[/]",
        subtitle="üî§ An√°lise Textual"
    ))

    # API Status
    api_status = "[green]Online[/]" if get_api_health() else "[red]Offline[/]"
    console.print(Panel.fit(
        f"üåê API: {api_status} | üè† Host: {API_CONFIG['host']} | "
        f"üîå Porta: {API_CONFIG['port']} | üîç ID: {vector_id}",
        title="[bold magenta]Informa√ß√µes da API[/]",
        subtitle="üöÄ Endpoint Status"
    ))

    # Normaliza√ß√£o do vetor
    scaler = MinMaxScaler()
    normalized_vector = scaler.fit_transform(np.array(vector_values).reshape(-1, 1)).flatten()

    # Processamento BERT - Convers√£o de tipo adicionada
    try:
        inputs = torch.tensor(np.round(normalized_vector).astype(np.int64)).unsqueeze(0).to(device)
        with torch.no_grad():
            outputs = model(inputs)
            hidden_states = outputs[0]
    except RuntimeError as e:
        console.print(f"[bold red]Erro durante o processamento BERT: {e}[/]")
        return

    # Layout principal
    layout = Layout()
    layout.split_column(
        Layout(name="header", size=3),
        Layout(name="main", size=30),
        Layout(name="footer", size=3)
    )
    layout["main"].split_row(
        Layout(name="left"),
        Layout(name="right")
    )
    layout["left"].split_column(Layout(name="left_top"), Layout(name="left_bottom"))
    layout["right"].split_column(Layout(name="right_top"), Layout(name="right_bottom"))

    # Grid 1: Informa√ß√µes do Vetor
    vector_info = Table(title="üìù Informa√ß√µes do Vetor", box=box.ROUNDED)
    vector_info.add_column("Campo", style="cyan")
    vector_info.add_column("Valor", style="green")
    
    vector_info.add_row("üîë ID", str(vector_id))
    vector_info.add_row("üìè Dimens√£o", str(len(vector_values)))
    vector_info.add_row("üíæ Tamanho em Mem√≥ria", f"{sys.getsizeof(vector_values)} bytes")
    vector_info.add_row("üî¢ Tipo de Dados", str(type(vector_values[0])))
    vector_info.add_row("üìä Shape", str(np.array(vector_values).shape))
    vector_info.add_row("üéØ Device", str(device))
    vector_info.add_row("ü§ñ Modelo BERT", "bert-base-multilingual-cased")
    vector_info.add_row("‚ö° GPU Dispon√≠vel", str(torch.cuda.is_available()))
    if torch.cuda.is_available():
        vector_info.add_row("üéÆ GPU Nome", torch.cuda.get_device_name(0))
        vector_info.add_row("üíæ GPU Mem√≥ria", f"{torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB")

    # Grid 2: An√°lise BERT Detalhada
    bert_analysis = Table(title="ü§ñ An√°lise BERT Detalhada", box=box.ROUNDED)
    bert_analysis.add_column("M√©trica", style="magenta")
    bert_analysis.add_column("Valor", style="yellow")
    
    tokens = tokenizer.encode(str(vector_values), add_special_tokens=True)
    token_words = tokenizer.convert_ids_to_tokens(tokens)
    
    bert_stats = {
        "üî§ Total Tokens": len(tokens),
        "üìù Tokens √önicos": len(set(tokens)),
        "üìä Densidade Token": len(set(tokens)) / len(tokens),
        "üîç Aten√ß√£o M√©dia": float(hidden_states.mean()),
        "üìà Aten√ß√£o M√°xima": float(hidden_states.max()),
        "üìâ Aten√ß√£o M√≠nima": float(hidden_states.min()),
        "üéØ Aten√ß√£o Std": float(hidden_states.std()),
        "üîÑ Entropia Aten√ß√£o": float(-torch.sum(hidden_states * torch.log2(hidden_states + 1e-10))),
        "üìä Dimens√£o Hidden": hidden_states.shape[-1],
        "üî¢ Camadas BERT": len(model.encoder.layer)
    }
    
    for metric, value in bert_stats.items():
        if isinstance(value, float):
            bert_analysis.add_row(metric, f"{value:.6f}")
        else:
            bert_analysis.add_row(metric, str(value))

    # Grid 3: Tokens e Palavras
    token_table = Table(title="üî§ An√°lise de Tokens", box=box.ROUNDED)
    token_table.add_column("Token", style="cyan")
    token_table.add_column("ID", style="green")
    token_table.add_column("Palavra", style="yellow")
    
    for token, token_id, word in zip(tokens[:10], range(len(tokens[:10])), token_words[:10]):
        token_table.add_row(str(token), str(token_id), word)

    # Grid 4: M√©tricas de Performance
    performance = Table(title="‚ö° M√©tricas de Performance", box=box.ROUNDED)
    performance.add_column("M√©trica", style="blue")
    performance.add_column("Valor", style="red")
    
    perf_stats = {
        "üñ•Ô∏è CPU Usage": f"{psutil.cpu_percent()}%",
        "üíæ Memory Usage": f"{psutil.virtual_memory().percent}%",
        "üîÑ Swap Usage": "N/A", # Valor padr√£o se houver erro
        "üíΩ Disk Usage": f"{psutil.disk_usage('/').percent}%",
        "üå°Ô∏è CPU Temp": f"{psutil.sensors_temperatures().get('coretemp', [{'current': 0}])[0]['current']}¬∞C" if hasattr(psutil, 'sensors_temperatures') else "N/A",
        "‚ö° Power Supply": "AC" if hasattr(psutil, 'sensors_battery') and psutil.sensors_battery() is None else "Battery",
        "üîå Network IO": f"{psutil.net_io_counters().bytes_sent/1e6:.2f}MB sent / {psutil.net_io_counters().bytes_recv/1e6:.2f}MB recv",
        "‚è±Ô∏è Boot Time": datetime.fromtimestamp(psutil.boot_time()).strftime("%Y-%m-%d %H:%M:%S"),
        "üë• Users": len(psutil.users()),
        "üîÑ Processes": len(psutil.pids())
    }
    
    try:
        perf_stats["üîÑ Swap Usage"] = f"{psutil.swap_memory().percent}%"
    except RuntimeError:
        pass # Ignora o erro

    for metric, value in perf_stats.items():
        performance.add_row(metric, str(value))

    # Exibir resultados
    with Live(layout, refresh_per_second=4):
        layout["header"].update(
            Panel("üî¨ An√°lise Detalhada de Vetores e Sistema", 
                  style="bold magenta")
        )
        layout["left_top"].update(Panel(vector_info))
        layout["left_bottom"].update(Panel(bert_analysis))
        layout["right_top"].update(Panel(token_table))
        layout["right_bottom"].update(Panel(performance))
        layout["footer"].update(
            Panel(f"‚è∞ An√°lise conclu√≠da em {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} | "
                  f"üñ•Ô∏è {sys_info['hostname']} | üåê {sys_info['ip']}")
        )

    # Progress bar com estat√≠sticas
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
    ) as progress:
        task1 = progress.add_task("[red]Processando vetores...", total=100)
        task2 = progress.add_task("[green]Analisando tokens...", total=100)
        task3 = progress.add_task("[blue]Calculando estat√≠sticas...", total=100)
        
        while not progress.finished:
            progress.update(task1, advance=0.9)
            progress.update(task2, advance=0.7)
            progress.update(task3, advance=0.5)

    # Salvar resultados
    results = {
        "timestamp": datetime.now().isoformat(),
        "system_info": sys_info,
        "api_info": {
            "status": api_status,
            "config": API_CONFIG
        },
        "vector_info": {
            "id": vector_id,
            "dimension": len(vector_values),
            "bert_stats": bert_stats,
            "performance": perf_stats
        }
    }
    
    with open(f'vector_analysis_{vector_id}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
        json.dump(results, f, indent=4)

def get_random_valid_id():
    """Obt√©m um ID aleat√≥rio v√°lido do banco de dados"""
    try:
        conn = sqlite3.connect('vectors_continuo.db')
        cursor = conn.cursor()
        cursor.execute("SELECT MIN(id), MAX(id) FROM word_vectors")
        min_id, max_id = cursor.fetchone()
        conn.close()
        return random.randint(min_id, max_id)
    except Exception as e:
        console.print(f"[red]Erro ao obter ID aleat√≥rio: {str(e)}[/]")
        return 1

def clear_console():
    """Limpa o console mantendo o hist√≥rico"""
    console.clear()

def run_continuous_analysis():
    """Executa a an√°lise em loop infinito"""
    iteration = 1
    
    try:
        while True:
            console.rule(f"[bold cyan]Itera√ß√£o #{iteration}")
            
            # Obt√©m ID aleat√≥rio
            vector_id = get_random_valid_id()
            
            try:
                # Tenta obter o vetor da API
                response = requests.get(f"{API_CONFIG['base_url']}/vectors/{vector_id}")
                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)
                data = response.json()
                vector_values = data['vector']
                word = data['word']
                palavra_origem = data.get('palavra_origem', 'N/A')
                    
                # Painel de informa√ß√µes da palavra atual
                console.print(Panel.fit(
                    f"[bold green]üéØ Analisando:[/]\n"
                    f"üìù Palavra: [bold yellow]{word}[/]\n"
                    f"üåç Origem: [bold blue]{palavra_origem}[/]\n"
                    f"üî¢ ID: [bold cyan]{vector_id}[/]",
                    title="[bold red]Palavra Atual[/]"
                ))
                    
                # Executa a an√°lise
                analyze_vector(vector_id, vector_values, word, palavra_origem)
                    
            except requests.exceptions.RequestException as e:
                console.print(f"[red]Erro de conex√£o com a API: {str(e)}")
                vector_values = [0] * 5
            except KeyError as e:
                console.print(f"[red]Erro na estrutura JSON da API: {str(e)}")
                vector_values = [0] * 5
            except Exception as e:
                console.print(f"[red]Erro inesperado ao processar a resposta da API: {str(e)}")
                vector_values = [0] * 5
            
            # Aguarda antes da pr√≥xima itera√ß√£o
            console.print("\n[cyan]Aguardando pr√≥xima an√°lise...[/]")
            
            # Barra de progresso para o intervalo com informa√ß√µes
            with Progress() as progress:
                task = progress.add_task(
                    f"[green]Pr√≥xima an√°lise em... (√öltima palavra: {word})", 
                    total=100
                )
                for _ in range(100):
                    time.sleep(0.1)  # 10 segundos total
                    progress.update(task, advance=1)
            
            # Limpa console mantendo hist√≥rico
            clear_console()
            
            iteration += 1
            
    except KeyboardInterrupt:
        console.print("\n[yellow]An√°lise interrompida pelo usu√°rio[/]")
        sys.exit(0)
    except Exception as e:
        console.print(f"[red]Erro inesperado: {str(e)}[/]")
        import traceback
        console.print("[red]" + traceback.format_exc() + "[/]")

if __name__ == "__main__":
    console.print(Panel.fit(
        "üîÑ Iniciando an√°lise cont√≠nua de vetores\n"
        "Pressione Ctrl+C para interromper\n\n"
        "[bold yellow]Informa√ß√µes adicionais:[/]\n"
        "- Convers√£o de vetores para palavras ativada\n"
        "- Compara√ß√£o palavra original vs. decodificada\n"
        "- Monitoramento de origem das palavras",
        title="[bold green]An√°lise Cont√≠nua[/]",
        subtitle="[bold red]Auto-refresh com Decodifica√ß√£o[/]"
    ))
    
    try:
        run_continuous_analysis()
    except KeyboardInterrupt:
        console.print("\n[yellow]Programa finalizado pelo usu√°rio[/]")
    except Exception as e:
        console.print(f"\n[red]Erro fatal: {str(e)}[/]")
        raise
