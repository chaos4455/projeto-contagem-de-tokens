## Documentação Técnica: `util.cleaner.advanced_duplicate_remover_PERSEUS.py`

> Documentação gerada em sábado, 02 de novembro de 2024 às 14 horas e 46 minutos

## Visão Geral

O script `util.cleaner.advanced_duplicate_remover_PERSEUS.py` é um limpador de arquivos avançado que detecta e remove arquivos duplicados de um sistema de arquivos, com foco em otimizar o espaço em disco e melhorar a organização. Ele é projetado para ser executado em sistemas Unix, incluindo macOS e Linux.

O script utiliza uma abordagem sofisticada para identificação de duplicatas, calculando hashes SHA256 para cada arquivo e, em seguida, mapeando esses hashes em um dicionário. Isso permite que ele identifique arquivos duplicados, mesmo que tenham nomes ou localizações diferentes.

## Estrutura e Componentes

O script é estruturado em torno da classe `LimpadorAvancado`, que contém os métodos e atributos necessários para realizar o processo de limpeza.

### Classe `LimpadorAvancado`

A classe `LimpadorAvancado` possui os seguintes membros e métodos:

- `pasta_backup`: O caminho para um diretório que servirá como backup para os arquivos removidos.
- `pasta_raiz`: O caminho para o diretório raiz a ser limpo.
- `hashes_raiz`: Um dicionário que mapeia hashes SHA256 para uma lista de informações de arquivos na raiz.
- `hashes_backup`: Um dicionário que mapeia hashes SHA256 para uma lista de informações de arquivos no diretório de backup.
- `total_removido`: O número de arquivos removidos durante o processo de limpeza.
- `espaco_liberado`: A quantidade de espaço em disco liberado durante o processo de limpeza.

### Métodos da Classe `LimpadorAvancado`

- `setup_logging()`: Configura o registro para o script.
- `calcular_hash_arquivo(caminho_arquivo)`: Calcula o hash SHA256 para o arquivo especificado por `caminho_arquivo`.
- `mapear_arquivos_raiz()`: Mapeia todos os arquivos na raiz, exceto aqueles em diretórios específicos (por exemplo, backup, venv, __pycache__, .git).
- `mapear_arquivos_backup()`: Mapeia todos os arquivos no diretório de backup.
- `remover_duplicados_internos()`: Remove arquivos duplicados dentro do diretório de backup, mantendo a versão mais recente.
- `remover_duplicados_da_raiz()`: Remove arquivos do diretório de backup que já existem na raiz.
- `_remover_arquivo(arquivo)`: Remove o arquivo especificado por `arquivo` e registra o evento.
- `remover_pastas_vazias_geral()`: Remove todas as pastas vazias do sistema de arquivos (raiz e backup).
- `gerar_relatorio()`: Gera um relatório final resumindo o processo de limpeza.
- `executar_limpeza()`: Executa todo o processo de limpeza.

## Fluxo de Execução Principal

O fluxo de execução principal do script é o seguinte:

1. Criar uma instância da classe `LimpadorAvancado`.
2. Mapear todos os arquivos na raiz e no diretório de backup, calculando hashes SHA256.
3. Remover arquivos duplicados dentro do diretório de backup (mantendo a versão mais recente).
4. Remover arquivos do diretório de backup que já existem na raiz.
5. Remover pastas vazias do sistema de arquivos.
6. Gerar um relatório final resumindo o processo de limpeza.

## Dependências e Requisitos

O script requer o seguinte software:

- Python 3.X
- hashlib
- pathlib
- datetime
- shutil

## Exemplos de Uso

O script pode ser usado executando o seguinte comando:

```
python util.cleaner.advanced_duplicate_remover_PERSEUS.py
```

## Considerações Técnicas Importantes

- O script pode ser executado em qualquer sistema Unix com Python 3.X instalado.
- O script pode levar um tempo significativo para ser executado, dependendo do número de arquivos no sistema de arquivos.
- É recomendável fazer backup dos arquivos antes de executar o script para evitar perda de dados.

## Possíveis Melhorias e Recomendações

- O script poderia ser otimizado para melhorar o desempenho em sistemas de arquivos maiores.
- O script poderia ser estendido para suportar a remoção de arquivos duplicados com base em outros critérios além de hashes SHA256 (por exemplo, tamanho do arquivo, data de modificação).

## Análise de Segurança e Performance

O script foi projetado para ser seguro e eficiente. Ele usa hashes SHA256 para identificar arquivos duplicados, o que é um método muito confiável. O script também é executado de forma incremental, o que reduz a sobrecarga do sistema.

## Licença

O script é licenciado sob a licença MIT.

## Autor

Elias Andrade - Evolução IT

## Contatos

* E-mail: oeliasandrade@gmail.com
* WhatsApp: (44) 9 8859-7116
* LinkedIn: [Perfil do LinkedIn](https://www.linkedin.com/in/itilmgf/)

## Repositórios Relacionados

* [Projeto no GitHub](https://github.com/evolucaoit/util.cleaner.advanced_duplicate_remover_PERSEUS)

## Citações

* "O futuro é agora, velho. Time flies, just like the Power Glove." - Back to the Future
* "A única coisa constante é a mudança." - Heráclito