from transformers import BertTokenizer, BertModel
import torch
import numpy as np
from rich.console import Console
from rich.layout import Layout
from rich.panel import Panel
from rich.table import Table
from rich.progress import track
from rich.live import Live
import numpy as np
from colorama import init, Fore, Back, Style
from sklearn.preprocessing import MinMaxScaler
import math
from datetime import datetime

# InicializaÃ§Ã£o
init()  # Colorama
console = Console()
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Carregar modelo BERT
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')
model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)

def analyze_vector(vector_values):
    """Analisa um vetor e retorna estatÃ­sticas detalhadas"""
    console.print(Panel.fit("ğŸ” Iniciando anÃ¡lise vetorial", 
                          title="[bold cyan]AnÃ¡lise de Vetores BERT[/]",
                          subtitle="ğŸ¤– Powered by Transformers"))

    # NormalizaÃ§Ã£o do vetor
    scaler = MinMaxScaler()
    normalized_vector = scaler.fit_transform(np.array(vector_values).reshape(-1, 1)).flatten()

    # Converter para tensor LongTensor e processar com BERT
    # Check for values outside the range of a LongTensor
    if np.any(normalized_vector < -2**31) or np.any(normalized_vector > 2**31 -1):
        console.print(f"[bold red]Error: Normalized vector contains values outside the range of a LongTensor. Please adjust the normalization method.[/]")
        return

    with torch.no_grad():
        inputs = torch.tensor(normalized_vector, dtype=torch.long).unsqueeze(0).to(device)
        outputs = model(inputs)
        hidden_states = outputs[0]

    # Criar layout
    layout = Layout()
    layout.split_column(
        Layout(name="header"),
        Layout(name="main"),
        Layout(name="footer")
    )
    layout["main"].split_row(Layout(name="grid1"), Layout(name="grid2"))
    layout["grid1"].split_row(Layout(name="grid1_1"), Layout(name="grid1_2"))
    layout["grid2"].split_row(Layout(name="grid2_1"), Layout(name="grid2_2"))


    # Grid 1: EstatÃ­sticas BÃ¡sicas
    stats_basic = Table(title="ğŸ“Š EstatÃ­sticas BÃ¡sicas", box=None)
    stats_basic.add_column("MÃ©trica", style="cyan")
    stats_basic.add_column("Valor", style="green")
    
    basic_stats = {
        "ğŸ”¢ DimensÃ£o": len(vector_values),
        "ğŸ“ˆ MÃ©dia": np.mean(vector_values),
        "ğŸ“‰ Desvio PadrÃ£o": np.std(vector_values),
        "â¬†ï¸ MÃ¡ximo": np.max(vector_values),
        "â¬‡ï¸ MÃ­nimo": np.min(vector_values),
        "â†”ï¸ Amplitude": np.ptp(vector_values),
        "ğŸ“Š Mediana": np.median(vector_values),
        "ğŸ¯ VariÃ¢ncia": np.var(vector_values),
        "ğŸ“ Norma L2": np.linalg.norm(vector_values),
        "ğŸ”„ Entropia": -np.sum(normalized_vector * np.log2(normalized_vector + 1e-10))
    }
    
    for metric, value in basic_stats.items():
        stats_basic.add_row(metric, f"{value:.6f}")

    # Grid 2: AnÃ¡lise BERT
    stats_bert = Table(title="ğŸ¤– AnÃ¡lise BERT", box=None)
    stats_bert.add_column("MÃ©trica", style="magenta")
    stats_bert.add_column("Valor", style="yellow")
    
    # TokenizaÃ§Ã£o e anÃ¡lise BERT
    tokens = tokenizer.encode(str(vector_values), add_special_tokens=True)
    bert_stats = {
        "ğŸ”¤ Total Tokens": len(tokens),
        "ğŸ“ Tokens Ãšnicos": len(set(tokens)),
        "ğŸ“Š Densidade Token": len(set(tokens)) / len(tokens),
        "ğŸ” AtenÃ§Ã£o MÃ©dia": float(hidden_states.mean()),
        "ğŸ“ˆ AtenÃ§Ã£o MÃ¡xima": float(hidden_states.max()),
        "ğŸ“‰ AtenÃ§Ã£o MÃ­nima": float(hidden_states.min()),
        "ğŸ¯ AtenÃ§Ã£o Std": float(hidden_states.std()),
        "ğŸ”„ Entropia AtenÃ§Ã£o": float(-torch.sum(hidden_states * torch.log2(hidden_states + 1e-10))),
        "ğŸ“Š DimensÃ£o Hidden": hidden_states.shape[-1],
        "ğŸ”¢ Camadas": len(model.encoder.layer)
    }
    
    for metric, value in bert_stats.items():
        if isinstance(value, float):
            stats_bert.add_row(metric, f"{value:.6f}")
        else:
            stats_bert.add_row(metric, str(value))

    # Grid 3: AnÃ¡lise Temporal
    stats_temporal = Table(title="â±ï¸ AnÃ¡lise Temporal", box=None)
    stats_temporal.add_column("MÃ©trica", style="blue")
    stats_temporal.add_column("Valor", style="red")
    
    # AnÃ¡lise de sÃ©ries temporais
    temporal_stats = {
        "ğŸ“ˆ TendÃªncia": np.polyfit(range(len(vector_values)), vector_values, 1)[0],
        "ğŸ”„ AutocorrelaÃ§Ã£o": np.correlate(vector_values, vector_values)[0],
        "ğŸ“Š Cruzamentos Zero": len(np.where(np.diff(np.signbit(vector_values)))[0]),
        "ğŸ“‰ Volatilidade": np.std(np.diff(vector_values)),
        "ğŸ¯ Momentum": sum(np.diff(vector_values)),
        "ğŸ” Periodicidade": len(np.fft.fft(vector_values)),
        "ğŸ“ˆ Pico FFT": np.max(np.abs(np.fft.fft(vector_values))),
        "âš¡ Energia": np.sum(np.square(vector_values)),
        "ğŸ”„ Ciclos": len(np.where(np.diff(np.signbit(np.diff(vector_values))))[0]),
        "ğŸ“Š Complexidade": np.sum(np.abs(np.diff(vector_values)))
    }
    
    for metric, value in temporal_stats.items():
        stats_temporal.add_row(metric, f"{value:.6f}")

    # Grid 4: MÃ©tricas AvanÃ§adas
    stats_advanced = Table(title="ğŸ“ MÃ©tricas AvanÃ§adas", box=None)
    stats_advanced.add_column("MÃ©trica", style="yellow")
    stats_advanced.add_column("Valor", style="cyan")
    
    # CÃ¡lculos avanÃ§ados
    vector_tensor = torch.tensor(vector_values, dtype=torch.float)
    advanced_stats = {
        "ğŸ” Kurtosis": float(((vector_tensor - vector_tensor.mean())**4).mean() / (vector_tensor.std()**4)),
        "ğŸ“Š Skewness": float(((vector_tensor - vector_tensor.mean())**3).mean() / (vector_tensor.std()**3)),
        "ğŸ“ˆ Densidade": len(np.nonzero(vector_values)[0]) / len(vector_values),
        "ğŸ¯ Coef. VariaÃ§Ã£o": np.std(vector_values) / np.mean(vector_values),
        "ğŸ”„ Shannon Entropy": -np.sum(normalized_vector * np.log2(normalized_vector + 1e-10)),
        "âš¡ Signal Power": np.mean(np.square(vector_values)),
        "ğŸ“‰ Dynamic Range": 20 * np.log10(np.max(np.abs(vector_values)) / (np.min(np.abs(vector_values)) + 1e-10)),
        "ğŸ” Sparsity": np.sum(np.abs(vector_values) < 1e-10) / len(vector_values),
        "ğŸ“Š Gini Index": np.sum(np.abs(vector_values)) / (len(vector_values) * np.mean(np.abs(vector_values))),
        "ğŸ¯ Hurst Exponent": 0.5  # Placeholder - implementaÃ§Ã£o completa requer mais dados
    }
    
    for metric, value in advanced_stats.items():
        if isinstance(value, float) and not math.isnan(value):
            stats_advanced.add_row(metric, f"{value:.6f}")
        else:
            stats_advanced.add_row(metric, "N/A")

    # Exibir resultados
    with Live(layout, refresh_per_second=4):
        layout["header"].update(Panel("ğŸ”¬ AnÃ¡lise Detalhada de Vetores"))
        layout["grid1_1"].update(Panel(stats_basic))
        layout["grid1_2"].update(Panel(stats_bert))
        layout["grid2_1"].update(Panel(stats_temporal))
        layout["grid2_2"].update(Panel(stats_advanced))
        layout["footer"].update(Panel(f"â° AnÃ¡lise concluÃ­da em {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"))

    # Barra de progresso colorida
    console.print("\n[bold green]AnÃ¡lise concluÃ­da com sucesso![/]")
    for i in track(range(10), description="[red]Finalizando anÃ¡lise..."):
        pass

if __name__ == "__main__":
    # Vetor de exemplo
    vector_values = [1.1924057130531671e-14, 7.15351953791486e-09, -1.6417647817581213e-13, 
                    2.406579822684353e-18, -6.152062841065303e-09]
    
    analyze_vector(vector_values)
