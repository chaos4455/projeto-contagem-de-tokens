# ğŸ¤– Projeto de GeraÃ§Ã£o de Embeddings com IA para RAG v0.0.0.4

[![MIT License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/)
[![Code Style: Black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Status](https://img.shields.io/badge/status-beta-yellow)]()
[![DocumentaÃ§Ã£o](https://img.shields.io/badge/docs-auto%20generated-green)]()

## ğŸ“‹ Ãndice
- [Sobre o Projeto](#sobre-o-projeto)
- [Novidades da VersÃ£o 0.0.0.4](#novidades-da-versÃ£o-00004)
- [Funcionalidades](#funcionalidades)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Arquitetura](#arquitetura)
- [Pipeline de Processamento](#pipeline-de-processamento)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Como Usar](#como-usar)
- [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
- [MÃ©tricas e Monitoramento](#mÃ©tricas-e-monitoramento)
- [SoluÃ§Ã£o de Problemas](#soluÃ§Ã£o-de-problemas)
- [FAQ](#faq)
- [ContribuiÃ§Ã£o](#contribuiÃ§Ã£o)
- [LicenÃ§a](#licenÃ§a)
- [Contato](#contato)


## ğŸ“Š MÃ©tricas e Monitoramento

- **Performance**: Tempo de processamento, taxa de throughput
- **Recursos**: CPU, RAM, GPU utilization
- **Qualidade**: Densidade semÃ¢ntica, precisÃ£o dos embeddings
- **Cache**: Hit rate, tamanho, eficiÃªncia
- **Tokens**: Contagem, distribuiÃ§Ã£o, custos

## ğŸ‘¥ Contato

**Elias Andrade - EvoluÃ§Ã£o IT**
- Email: oeliasandrade@gmail.com
- LinkedIn: https://www.linkedin.com/in/itilmgf/
- WhatsApp: (11) 9 8859-7116

### RepositÃ³rios
- Pessoal: https://github.com/chaos4455
- Empresa: https://github.com/evolucaoit
- IA/AutomaÃ§Ã£o: https://github.com/replika-ai-solutions

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT.

# ğŸš€ Projeto de AutomaÃ§Ã£o e AnÃ¡lise de Embeddings v0.0.0.4

**Arquiteto:** Elias Andrade  
**Status:** Beta  
**VersÃ£o:** 0.0.0.4  
**Data:** 02/11/2024

## ğŸ†• Novidades da VersÃ£o 0.0.0.4

- ğŸ¤– IntegraÃ§Ã£o com Google Gemini API
- âš¡ Processamento assÃ­ncrono aprimorado
- ğŸ“Š Sistema de logs estruturados
- ğŸ”„ Versionamento automÃ¡tico de documentaÃ§Ã£o
- ğŸ› ï¸ Tratamento de erros robusto

### ğŸŒŸ Destaques TÃ©cnicos

- **Gemini Integration**: ImplementaÃ§Ã£o da API Gemini Pro para anÃ¡lise avanÃ§ada de cÃ³digo
- **Async/Await**: OtimizaÃ§Ã£o do processamento paralelo
- **Error Handling**: Sistema robusto de tratamento de erros com retry
- **Logging**: Sistema de logs estruturados com rotaÃ§Ã£o de arquivos

## ğŸ”„ Pipeline de DocumentaÃ§Ã£o v2

1. **Coleta de Dados**
   - AnÃ¡lise de arquivos Python
   - AnÃ¡lise de estruturas de banco de dados
   - Processamento de markdown existente

2. **Processamento**
   - AnÃ¡lise com IA (Gemini)
   - GeraÃ§Ã£o de documentaÃ§Ã£o tÃ©cnica
   - Versionamento automÃ¡tico

3. **SaÃ­da**
   - Markdown rico e estilizado
   - Badges e shields dinÃ¢micos
   - Diagramas ASCII art

# ğŸ—ï¸ Arquitetura do Sistema v0.0.0.3

## ğŸ¯ VisÃ£o Arquitetural v2

### ğŸ”„ Fluxo Principal do Sistema
1. ğŸ“¥ **Entrada de Dados v2**
   - ğŸ“ ValidaÃ§Ã£o YAML avanÃ§ada
   - âš™ï¸ ConfiguraÃ§Ãµes dinÃ¢micas
   - ğŸšï¸ ParÃ¢metros adaptativos

2. ğŸ§® **Processamento Central v3**
   - ğŸ¤– Motor de IA otimizado
   - ğŸ”„ Stream Processing paralelo
   - ğŸ“Š AnÃ¡lise preditiva de tokens

3. ğŸ“¤ **SaÃ­da e Armazenamento v2**
   - ğŸ’¾ Backup Incremental Inteligente
   - ğŸ“ OrganizaÃ§Ã£o HierÃ¡rquica
   - ğŸ“ Logs Estruturados

### ğŸ› ï¸ Novos Componentes v2
- ğŸ§¹ Sistema de Limpeza AvanÃ§ada
- ğŸ“Š MÃ©tricas em Tempo Real
- ğŸ”„ Backup Incremental v2
- ğŸ¤– IntegraÃ§Ã£o PaLM/Gemini v2

### ğŸ”’ SeguranÃ§a v2
- ğŸ” EncriptaÃ§Ã£o AvanÃ§ada
- ğŸ·ï¸ Versionamento Seguro v2
- ğŸ“ Logs Protegidos
- ğŸ” Auditoria em Tempo Real


## ğŸ†• Novidades da VersÃ£o 0.0.0.4

- ğŸ¤– **IntegraÃ§Ã£o Google Gemini API**: Suporte avanÃ§ado para geraÃ§Ã£o de embeddings
- âš¡ **Processamento AssÃ­ncrono Aprimorado**: Melhor performance e escalabilidade
- ğŸ“Š **Sistema de Logs Estruturados**: Monitoramento detalhado
- ğŸ”„ **Versionamento AutomÃ¡tico**: Controle de versÃµes da documentaÃ§Ã£o
- ğŸ› ï¸ **Tratamento de Erros Robusto**: Sistema de retry e fallback
- ğŸ§® **Analytics AvanÃ§ado**: Novos KPIs e mÃ©tricas personalizadas

# âš¡ Processamento AssÃ­ncrono v0.0.0.4

## ğŸ”„ Pipeline AssÃ­ncrono

### ğŸ“¥ Entrada
- Leitura assÃ­ncrona de arquivos
- Processamento paralelo de mÃºltiplos arquivos
- Queue management

### ğŸ”„ Processamento
- AnÃ¡lise IA com retry
- GeraÃ§Ã£o de documentaÃ§Ã£o paralela
- Controle de concorrÃªncia

### ğŸ“¤ SaÃ­da
- Escrita assÃ­ncrona de arquivos
- Versionamento automÃ¡tico
- GestÃ£o de backups

## ğŸ¯ Melhorias Implementadas

### âš¡ Performance
- ThreadPoolExecutor para processamento paralelo
- Controle de taxa de requisiÃ§Ãµes
- OtimizaÃ§Ã£o de memÃ³ria

### ğŸ› ï¸ Error Handling
- Retry automÃ¡tico com backoff
- Logging estruturado
- RecuperaÃ§Ã£o de falhas

### ğŸ“Š Monitoramento
- MÃ©tricas de performance
- Logs detalhados
- Status de processamento em tempo real 

## ğŸ¯ Sobre o Projeto

Este projeto Ã© uma soluÃ§Ã£o avanÃ§ada para geraÃ§Ã£o de embeddings vetoriais utilizando IA, especialmente projetado para alimentar sistemas RAG (Retrieval-Augmented Generation). O sistema processa documentos em YAML, gera embeddings utilizando modelos BERT e oferece uma interface rica para visualizaÃ§Ã£o e anÃ¡lise de mÃ©tricas em tempo real.  Ele foi desenvolvido com foco em eficiÃªncia, escalabilidade e facilidade de uso, permitindo o processamento de grandes conjuntos de dados de forma eficiente.

### ğŸŒŸ Principais CaracterÃ­sticas

- GeraÃ§Ã£o de embeddings vetoriais de alta qualidade utilizando modelos prÃ©-treinados de Ãºltima geraÃ§Ã£o.
- Processamento em stream para grandes volumes de dados, permitindo o processamento de arquivos YAML de qualquer tamanho sem sobrecarregar a memÃ³ria.
- IntegraÃ§Ã£o com mÃºltiplos modelos de IA (BERT, Sentence Transformers, e potencialmente outros modelos via APIs), oferecendo flexibilidade e adaptabilidade a diferentes necessidades.
- Interface rica com a biblioteca Rich, fornecendo uma experiÃªncia de usuÃ¡rio intuitiva e informativa com mÃ©tricas em tempo real.
- OtimizaÃ§Ã£o de recursos computacionais atravÃ©s do uso de processamento paralelo (multithreading e multiprocessing), reduzindo o tempo de processamento.
- Cache inteligente de embeddings para evitar cÃ¡lculos redundantes e acelerar o processamento subsequente.
- Suporte a processamento paralelo para maximizar o uso de recursos multi-core.
- Robustez e tratamento de erros para garantir a estabilidade do sistema.


## ğŸ›  Funcionalidades

### Processamento de Dados
- **ConversÃ£o de documentos YAML para embeddings:** O sistema lÃª arquivos YAML contendo texto e gera embeddings vetoriais correspondentes.  Suporta diferentes estruturas de YAML, desde listas simples atÃ© estruturas complexas aninhadas.
- **TokenizaÃ§Ã£o avanÃ§ada com BERT:** Utiliza o modelo BERT para tokenizar o texto, considerando o contexto e a semÃ¢ntica das palavras.  Isso garante uma representaÃ§Ã£o vetorial mais precisa e significativa.
- **AnÃ¡lise semÃ¢ntica com Sentence Transformers:** Emprega modelos Sentence Transformers para capturar a semÃ¢ntica do texto, resultando em embeddings que refletem melhor o significado do conteÃºdo.
- **Cache de embeddings para otimizaÃ§Ã£o:** Armazena os embeddings gerados em cache para evitar cÃ¡lculos repetidos, melhorando significativamente o desempenho, especialmente para grandes conjuntos de dados com textos repetidos ou similares.  O cache Ã© persistido em disco para uso em sessÃµes subsequentes.

### MÃ©tricas e AnÃ¡lises
- **Contagem de tokens:** Fornece a contagem precisa de tokens para cada documento processado, permitindo o monitoramento do tamanho do texto e a otimizaÃ§Ã£o do uso de recursos.
- **AnÃ¡lise de densidade semÃ¢ntica:** Calcula a densidade semÃ¢ntica dos embeddings, fornecendo insights sobre a riqueza e complexidade do conteÃºdo.
- **Monitoramento de recursos (CPU, GPU, MemÃ³ria):** Monitora o uso de recursos do sistema em tempo real, permitindo a identificaÃ§Ã£o de gargalos e a otimizaÃ§Ã£o do desempenho.
- **EstatÃ­sticas de processamento em tempo real:** Exibe estatÃ­sticas de processamento, como tempo de processamento, taxa de processamento e progresso geral.

### VisualizaÃ§Ã£o
- **Interface rica com Rich library:** Utiliza a biblioteca Rich para criar uma interface de linha de comando (CLI) interativa e visualmente atraente.
- **PainÃ©is interativos:** Apresenta painÃ©is interativos que permitem a navegaÃ§Ã£o e a anÃ¡lise das mÃ©tricas.
- **GrÃ¡ficos de progresso:** Exibe grÃ¡ficos de progresso em tempo real, mostrando o andamento do processamento.
- **Indicadores de performance:** Fornece indicadores de performance chave (KPIs) para monitorar a eficiÃªncia do sistema.


## ğŸ”§ Tecnologias Utilizadas

- **Python 3.9+:** Linguagem de programaÃ§Ã£o principal.
- **BERT (bert-base-uncased):** Modelo de linguagem prÃ©-treinado para tokenizaÃ§Ã£o e geraÃ§Ã£o de embeddings.
- **Sentence Transformers:** Biblioteca para gerar embeddings semÃ¢nticos de alta qualidade.
- **Google Gemini API (opcional):**  IntegraÃ§Ã£o opcional com a API do Google Gemini para geraÃ§Ã£o de embeddings ainda mais avanÃ§ados. (Requer chave de API)
- **PyTorch:** Framework para processamento de dados e cÃ¡lculos de embeddings.
- **NLTK:** Biblioteca para processamento de linguagem natural (NLP).
- **Rich:** Biblioteca para criar interfaces de usuÃ¡rio ricas e interativas na linha de comando.
- **YAML:** Formato de dados utilizado para entrada e saÃ­da de documentos.
- **Asyncio:** Biblioteca para programaÃ§Ã£o assÃ­ncrona, otimizando o processamento de dados.
- **Threading e Multiprocessing:** TÃ©cnicas de processamento paralelo para acelerar o processamento.
- **SQLite:** Banco de dados para armazenamento persistente de embeddings (opcional, para cache).


## ğŸ— Arquitetura

O projeto segue uma arquitetura modular, organizada em diferentes mÃ³dulos para facilitar a manutenÃ§Ã£o e a extensÃ£o. Os principais componentes sÃ£o:

- **MÃ³dulo de PrÃ©-processamento:** ResponsÃ¡vel pela leitura dos arquivos YAML, limpeza de dados e tokenizaÃ§Ã£o do texto.
- **MÃ³dulo de GeraÃ§Ã£o de Embeddings:** Gera os embeddings vetoriais utilizando os modelos BERT e Sentence Transformers.
- **MÃ³dulo de Cache:** Armazena os embeddings gerados em cache para otimizar o desempenho.
- **MÃ³dulo de Monitoramento:** Monitora o uso de recursos e coleta mÃ©tricas de desempenho.
- **MÃ³dulo de VisualizaÃ§Ã£o:** Exibe as mÃ©tricas e os resultados atravÃ©s da interface CLI com a biblioteca Rich.
- **Banco de Dados SQLite:** Armazena os tokens e embeddings gerados.

A comunicaÃ§Ã£o entre os mÃ³dulos Ã© feita atravÃ©s de uma interface bem definida, permitindo a substituiÃ§Ã£o de componentes sem afetar o funcionamento do sistema como um todo.  O design segue os princÃ­pios SOLID para garantir a manutenibilidade e a escalabilidade do cÃ³digo.

![Cursor_mvmaoYHBLG](https://github.com/user-attachments/assets/737aa609-f539-49dd-8135-4b0c60f74481)

![Cursor_Df7tQrj21A](https://github.com/user-attachments/assets/245b3ff5-902b-47fa-84d3-be4f4200c7e9)

![Cursor_YgJPNCky0X](https://github.com/user-attachments/assets/45dfe03e-bd7b-4669-aaa8-12cba53edd6b)

![Cursor_yE7siYz8tb](https://github.com/user-attachments/assets/2879f4db-c98b-4af1-8f01-ce5ad7f48890)

![Cursor_J37Yg5HPpS](https://github.com/user-attachments/assets/4bf36e23-a87f-403c-a0a6-87fb964d8ecd)

![Cursor_tbGFu8YfAX](https://github.com/user-attachments/assets/1465df9c-cc8d-4dfe-9cb1-73179ea90f7e)

![Cursor_EDfjSB1EXx](https://github.com/user-attachments/assets/2385bea4-8b7a-4ef6-b694-60265c51774d)

![Cursor_AJORiyMeec](https://github.com/user-attachments/assets/672c7fdd-368e-471e-ba0e-9ca3f20e6777)

![Cursor_bPdAl3i8a1](https://github.com/user-attachments/assets/47e92718-8f99-418c-af99-c888e17207c2)

![Cursor_0zTjXWxVMF](https://github.com/user-attachments/assets/47d10a7c-b53d-4a9b-9cbf-47f80d915ee4)

![Cursor_NrFpgAv6vu](https://github.com/user-attachments/assets/50d8bf54-0d3d-487c-a992-0812abbc3a53)

![Cursor_x2nTwEHCAn](https://github.com/user-attachments/assets/c79f4cd7-c8af-49b2-9ae8-e9e2aa3df688)

![Cursor_iSzOSpcTHu](https://github.com/user-attachments/assets/a50b220a-0768-44af-b2a0-81b7d9b392a6)

![Cursor_Dhv29Ht5K5](https://github.com/user-attachments/assets/5833b98f-0eb0-4198-be0d-863fa7750be0)

![Cursor_ZIyXfk8i9g](https://github.com/user-attachments/assets/2b1e136c-ae6e-4b0e-805f-ca0b8c3d2fc4)

![Cursor_VLyZvswGOw](https://github.com/user-attachments/assets/9074d452-06fb-44a2-a595-888008ed23e6)

![Cursor_fxzXRcfiOV](https://github.com/user-attachments/assets/32152b15-1e8b-4a63-b001-b864ef2195e3)

![Cursor_EgiVmqIsSz](https://github.com/user-attachments/assets/961f8c2f-7b8d-49d7-9d43-e25736764356)

![Cursor_OjBywR8RJ3](https://github.com/user-attachments/assets/a22a2caa-8a29-4dfe-a378-b109273eb0f0)

![Cursor_1PDjZOHXM9](https://github.com/user-attachments/assets/ff99b80a-d0d1-4207-82ba-7a59a75864ac)

![Cursor_He8dFagem3](https://github.com/user-attachments/assets/9eba389a-bd47-4834-83c4-3964110f682a)

![Cursor_baHA9OCOSE](https://github.com/user-attachments/assets/f2943b38-2fbb-474d-9e67-489ae241e6bb)

![Cursor_euDOSJgsSN](https://github.com/user-attachments/assets/830f0499-0013-4dab-9db2-dfbe1b1c0241)

![Cursor_y4ykB5cXRH](https://github.com/user-attachments/assets/ccd860fd-b1ef-4856-b119-3888ab71f8c8)

![Cursor_57e2JgBSKT](https://github.com/user-attachments/assets/6dfbf009-7fc9-4769-81a6-4ebdcfb46d73)

![Cursor_s84ZZ1zWM0](https://github.com/user-attachments/assets/108146c6-d0bd-45f8-9548-a21a94f85391)

![Cursor_qpgN6rRJ0l](https://github.com/user-attachments/assets/b3ba0834-f650-4ab6-9616-644788fad911)

![Cursor_a3FUNFT526](https://github.com/user-attachments/assets/7e760811-58e7-4944-a2b7-5ea885c450a1)

## ğŸ¬ Como Usar

1. **Prepare seus dados:** Organize seus dados em arquivos YAML, com cada arquivo contendo um ou mais documentos.
2. **Execute o script principal:** `python main.py --input_dir <caminho_para_seus_arquivos_yaml>`
3. **Monitore o progresso:** A interface Rich exibirÃ¡ o progresso do processamento, as mÃ©tricas e os resultados.
4. **Analise os resultados:** Os embeddings gerados serÃ£o salvos em um banco de dados SQLite (ou em memÃ³ria, dependendo da configuraÃ§Ã£o).  VocÃª pode acessar os embeddings e as mÃ©tricas atravÃ©s da interface.


## âš™ï¸ ConfiguraÃ§Ã£o

O arquivo `config.yaml` permite configurar diversos aspectos do projeto, incluindo:

- `input_dir`: Caminho para a pasta contendo os arquivos YAML de entrada.
- `output_dir`: Caminho para a pasta onde os resultados serÃ£o salvos.
- `model_name`: Nome do modelo BERT a ser utilizado.
- `cache_size`: Tamanho mÃ¡ximo do cache de embeddings (em MB).
- `num_workers`: NÃºmero de workers para processamento paralelo.
- `use_gemini_api`:  `true` ou `false` para habilitar/desabilitar a API do Google Gemini.
- `gemini_api_key`: Chave de API do Google Gemini (se `use_gemini_api` for `true`).


## ğŸ“Š MÃ©tricas e Monitoramento

O sistema monitora e exibe as seguintes mÃ©tricas:

- **Tempo de processamento:** Tempo total gasto para processar todos os documentos.
- **Taxa de processamento:** NÃºmero de documentos processados por segundo.
- **Uso de CPU:** Porcentagem de uso da CPU durante o processamento.
- **Uso de RAM:** Quantidade de memÃ³ria RAM utilizada durante o processamento.
- **Tamanho do cache:** Tamanho atual do cache de embeddings.
- **NÃºmero de tokens:** Contagem total de tokens processados.
- **Densidade semÃ¢ntica mÃ©dia:** Densidade semÃ¢ntica mÃ©dia dos embeddings gerados.


## ğŸ SoluÃ§Ã£o de Problemas

- **Erro de importaÃ§Ã£o de bibliotecas:** Certifique-se de ter instalado todas as dependÃªncias listadas em `requirements.txt`.
- **Erro de conexÃ£o com a API do Google Gemini:** Verifique sua chave de API e sua conexÃ£o com a internet.
- **Erro de processamento de arquivos YAML:** Certifique-se de que seus arquivos YAML estÃ£o bem formatados.
- **Uso excessivo de memÃ³ria:** Aumente o tamanho do cache ou reduza o nÃºmero de workers.


## â“ Perguntas Frequentes (FAQ)

- **Qual o tamanho mÃ¡ximo de arquivo YAML que o sistema suporta?**  O sistema suporta arquivos YAML de qualquer tamanho, graÃ§as ao processamento em stream.
- **Posso usar outros modelos de linguagem alÃ©m do BERT?**  Sim, o sistema pode ser adaptado para usar outros modelos, desde que sejam compatÃ­veis com a biblioteca Sentence Transformers.
- **Como posso contribuir para o projeto?**  Veja a seÃ§Ã£o "ContribuiÃ§Ã£o".


## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas!  Por favor, abra um pull request com suas alteraÃ§Ãµes.


## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT.
## ğŸ“œ Scripts do Projeto

Esta seÃ§Ã£o descreve os scripts Python principais do projeto:

### `automacao_organiza_projeto_restaura_backup_v1.py`

Este script automatiza o processo de backup, restauraÃ§Ã£o e organizaÃ§Ã£o dos arquivos do projeto. Ele utiliza a biblioteca `rich` para exibir mensagens formatadas no console e `logging` para registrar eventos.  As principais funcionalidades incluem:

- **Backup:** Cria um backup completo do projeto.
- **RestauraÃ§Ã£o:** Restaura um backup anterior.
- **OrganizaÃ§Ã£o:** Organiza os arquivos em pastas especÃ­ficas por extensÃ£o (`.log`, `.txt`, `.json`, `.zip`).
- **Tratamento de Duplicatas:** Renomeia arquivos com nomes duplicados, adicionando um hash Ãºnico ao nome.
- **Monitoramento:** Exibe o progresso e as estatÃ­sticas da automaÃ§Ã£o.

### `backup_projeto.py`

Este script cria um backup completo do projeto em um arquivo ZIP. Ele calcula o tamanho da pasta, gera um hash Ãºnico para cada backup, obtÃ©m a Ãºltima versÃ£o do backup e usa a biblioteca `rich` para criar um dashboard visual com as estatÃ­sticas do backup.  Ele tambÃ©m inclui tratamento de erros e logging.

### `banco_tokens.py`

Este script define funÃ§Ãµes para interagir com um banco de dados SQLite que armazena tokens e embeddings gerados pelo sistema.  As funÃ§Ãµes principais sÃ£o:

- `create_database()`: Cria o banco de dados SQLite se ele nÃ£o existir.
- `generate_unique_hash(input_text)`: Gera um hash SHA256 Ãºnico para um dado texto.
- `analyze_bert(text, model_name="bert-base-uncased")`: Usa o modelo BERT para gerar tokens e embeddings para um dado texto.
- `insert_data(input_text, tokens, embeddings, db_name="tokens_database.db")`: Insere os dados (timestamp, hash Ãºnico, texto, tokens e embeddings) no banco de dados.

### `contador_tokens_menu.py`

Este script fornece um menu interativo para analisar tokens e embeddings. Ele permite ao usuÃ¡rio escolher entre vÃ¡rias aÃ§Ãµes, incluindo analisar vetores brutos, listar IDs aleatÃ³rios ou especÃ­ficos, analisar indicadores estatÃ­sticos, calcular a similaridade de cosseno entre vetores, exibir KPIs e sair.  Ele usa as bibliotecas `inquirer`, `colorama`, `matplotlib` e `scipy`.

### `gerador_yaml_embeddings_stream_v1.py`

Este script gera arquivos YAML usando a API do Google Gemini em modo de streaming. Ele inclui processamento de tokens BERT em threads separadas, monitoramento de recursos do sistema e um painel de estatÃ­sticas em tempo real usando a biblioteca `rich`.  Ele tambÃ©m calcula mÃ©tricas avanÃ§adas, como densidade semÃ¢ntica e diversidade lexical.  As principais caracterÃ­sticas incluem:

- **GeraÃ§Ã£o de YAML em Streaming:** Gera arquivos YAML usando a API do Google Gemini com streaming para lidar com grandes quantidades de texto.
- **Processamento de Tokens BERT Multi-threaded:** Utiliza o modelo BERT para tokenizar o texto em paralelo, melhorando o desempenho.
- **Monitoramento de Recursos:** Monitora o uso de CPU, memÃ³ria e GPU (se disponÃ­vel) em tempo real.
- **Painel de EstatÃ­sticas:** Exibe um painel interativo com estatÃ­sticas de processamento, incluindo contagem de tokens, palavras, tempo de processamento, uso de recursos e outras mÃ©tricas.
- **MÃ©tricas AvanÃ§adas:** Calcula mÃ©tricas como densidade semÃ¢ntica, diversidade lexical e outras mÃ©tricas relevantes para anÃ¡lise de texto.

## ğŸ“ Notas de VersÃ£o

### VersÃ£o 0.0.0.2 (01/01/2024 07:33)

- **AtualizaÃ§Ãµes:**  Esta versÃ£o inclui todas as alteraÃ§Ãµes realizadas desde o inÃ­cio do projeto atÃ© a data de 01/01/2024 07:33.  Uma anÃ¡lise completa do cÃ³digo-fonte Ã© necessÃ¡ria para detalhar as mudanÃ§as especÃ­ficas.  [Inserir aqui um detalhamento das mudanÃ§as, se possÃ­vel].

