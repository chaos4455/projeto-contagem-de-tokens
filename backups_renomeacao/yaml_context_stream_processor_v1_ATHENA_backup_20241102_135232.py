import yaml
import hashlib
from datetime import datetime, timedelta
import google.generativeai as genai
import os
from pathlib import Path
import time
from colorama import init, Fore, Style, Back
from rich.console import Console
from rich.panel import Panel
from rich.live import Live
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich.layout import Layout
from rich.columns import Columns
from rich.align import Align
from collections import Counter, deque
from rich.style import Style
from rich.text import Text
from rich.padding import Padding
import nltk
from nltk.tokenize import word_tokenize
import statistics
import asyncio
from transformers import BertTokenizer, BertModel
import torch
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import Dict, List
import psutil
import GPUtil
from rich.console import Console
from rich.panel import Panel
from rich.live import Live
from rich.table import Table
from rich.layout import Layout
from rich.align import Align
from rich.text import Text
from rich.box import ROUNDED, HEAVY, SIMPLE  # ImportaÃ§Ã£o correta dos boxes
from psutil import cpu_percent, virtual_memory, disk_usage
import platform
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
from threading import Thread
import multiprocessing
from functools import partial
from dataclasses import dataclass
from collections import defaultdict
import aiofiles
from contextlib import suppress

# Download necessÃ¡rio do NLTK
nltk.download('punkt', quiet=True)

# InicializaÃ§Ã£o
init(autoreset=True)
console = Console()

# Emojis e Ã­cones
EMOJI = {
    "stream": "ğŸŒŠ",
    "token": "ğŸ¯",
    "palavra": "ğŸ“",
    "letra": "ğŸ“Š",
    "tempo": "â±ï¸",
    "arquivo": "ğŸ—‚",
    "stats": "ğŸ“ˆ",
    "max": "â¬†ï¸",
    "min": "â¬‡ï¸",
    "media": "â¡ï¸",
    "total": "ğŸ’¯",
    "velocidade": "ğŸš€",
    "memoria": "ğŸ’¾",
    "processando": "âš¡"
}

# ğŸ”‘ ConfiguraÃ§Ã£o da API
API_KEY = "AIzaSyCEagEEnX-RdkW3-jCAb0H9nrTsgcE-Qqo"
genai.configure(api_key=API_KEY)

# ğŸ¯ ConfiguraÃ§Ãµes do modelo
NOME_MODELO = "gemini-1.5-flash"
CONFIG_GERACAO = {
    "temperature": 0.8,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 8096,
}

# ConfiguraÃ§Ãµes Globais
TOKEN_COUNTER = True  # Define se a anÃ¡lise de tokens BERT serÃ¡ realizada (True/False)

@dataclass
class TokenBatch:
    """Estrutura para batch de tokens"""
    text: str
    timestamp: float
    batch_id: int

class AdvancedMetrics:
    def __init__(self):
        try:
            self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
            self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
        except Exception as e:
            console.print(f"[yellow]Aviso: Usando fallback para tokenizaÃ§Ã£o: {str(e)}[/yellow]")
            self.bert_tokenizer = None
            self.sentence_model = None
            
        self.embedding_dim = 384
        self.embedding_cache = {}
        self.token_frequency = {}
        self.sentence_lengths = []
        self.embedding_magnitudes = []
        self.token_diversity = 0.0
        self.semantic_density = 0.0
        self.cpu_usage = 0.0
        self.memory_usage = 0.0
        self.gpu_usage = 0.0

class SystemMonitor:
    """Monitora recursos do sistema com fallbacks"""
    def __init__(self):
        self.os_type = platform.system()
        self.fallback_mode = False
        
        # Tenta inicializar contadores
        try:
            self.cpu_percent = psutil.cpu_percent(interval=0.1)
            self.cpu_per_core = psutil.cpu_percent(percpu=True)
        except Exception as e:
            console.print(f"[yellow]âš ï¸ Usando modo fallback para mÃ©tricas de CPU[/yellow]")
            self.fallback_mode = True

    def get_cpu_stats(self):
        """ObtÃ©m estatÃ­sticas de CPU com fallback"""
        try:
            if self.fallback_mode:
                # Fallback usando /proc no Linux ou wmic no Windows
                if self.os_type == "Linux":
                    with open('/proc/stat', 'r') as f:
                        cpu_lines = f.readlines()
                    return {
                        'total': float(cpu_lines[0].split()[1]),
                        'cores': [float(line.split()[1]) for line in cpu_lines[1:] if line.startswith('cpu')]
                    }
                else:
                    # Windows fallback
                    return {
                        'total': os.getloadavg()[0] if hasattr(os, 'getloadavg') else 0,
                        'cores': [0] * psutil.cpu_count()
                    }
            else:
                return {
                    'total': psutil.cpu_percent(interval=0.1),
                    'cores': psutil.cpu_percent(percpu=True)
                }
        except Exception:
            return {'total': 0, 'cores': [0] * psutil.cpu_count()}

    def get_memory_stats(self):
        """ObtÃ©m estatÃ­sticas de memÃ³ria com fallback"""
        try:
            mem = psutil.virtual_memory()
            swap = psutil.swap_memory()
            return {
                'used': mem.used,
                'total': mem.total,
                'percent': mem.percent,
                'swap_percent': swap.percent
            }
        except Exception:
            return {
                'used': 0,
                'total': 0,
                'percent': 0,
                'swap_percent': 0
            }

class StreamStats:
    def __init__(self):
        self.metrics = AdvancedMetrics()
        # Contadores bÃ¡sicos
        self.caracteres = 0
        self.palavras = 0
        self.tokens_bert = 0
        self.palavras_unicas = set()
        self.token_unicos = set()
        self.maiores_palavras = []
        self.ultimas_palavras = deque(maxlen=10)
        self.inicio = time.time()
        self.chars_por_segundo = 0
        self.palavras_por_segundo = 0
        self.tokens_por_segundo = 0
        self.buffer = ""
        
        # Controle de iteraÃ§Ã£o
        self.iteracao_atual = 0
        self.total_iteracoes = 20
        self.ultimo_arquivo = ""
        
        # MÃ©tricas calculadas
        self.media_tamanho_palavras = 0
        self.diversidade_lexica = 0
        self.token_ratio = 0
        
        # Inicializa mÃ©tricas do sistema
        self.atualizar_metricas_sistema()

        # InicializaÃ§Ã£o condicional do tokenizador BERT
        self.bert_enabled = TOKEN_COUNTER
        if self.bert_enabled:
            try:
                console.print("[cyan]ğŸ¯ Token Counter: ATIVADO - Iniciando BERT...[/cyan]")
                self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
                self.tokens_bert = 0
                self.token_unicos = set()
                self.token_frequency = {}
                self.tokens_por_segundo = 0
                self.token_stats = {
                    'media_len': 0,
                    'max_len': 0,
                    'subwords_ratio': 0,
                    'special_tokens': 0
                }
                console.print("[green]âœ… BERT inicializado com sucesso![/green]")
            except Exception as e:
                console.print(f"[yellow]âš ï¸ Aviso: Erro ao inicializar BERT: {e}[/yellow]")
                self.bert_tokenizer = None
        else:
            console.print("[yellow]âš ï¸ Token Counter: DESATIVADO - BERT nÃ£o serÃ¡ utilizado[/yellow]")
            self.bert_tokenizer = None

        self.system_monitor = SystemMonitor()

        # Adicionar atributos faltantes
        self.sentences = []
        self.embedding_stats = {
            'min_magnitude': 0,
            'max_magnitude': 0,
            'avg_magnitude': 0
        }
        self.top_tokens = []  # Lista para os tokens mais frequentes
        self.eficiencia_tokens = 0.0
        self.cobertura_vocab = 0.0
        self.densidade_texto = 0.0
        self.performance_score = 0.0

    def safe_div(self, n, d):
        """DivisÃ£o segura com valor default 0"""
        try:
            if d == 0:
                return 0.0
            result = float(n) / float(d)
            return result if result != float('inf') else 0.0
        except:
            return 0.0

    def safe_mean(self, values):
        """MÃ©dia segura com verificaÃ§Ãµes"""
        try:
            cleaned_values = [float(v) for v in values if v is not None and str(v).strip()]
            return np.mean(cleaned_values) if cleaned_values else 0.0
        except:
            return 0.0

    async def atualizar(self, novo_texto: str, iteracao: int = 0, arquivo: str = ""):
        """Atualiza estatÃ­sticas com novo texto"""
        try:
            if not novo_texto:
                return
                
            # Atualiza controle de iteraÃ§Ã£o
            self.iteracao_atual = iteracao
            if arquivo:
                self.ultimo_arquivo = Path(arquivo).name
            
            # Atualiza contadores bÃ¡sicos
            self.buffer += novo_texto
            self.caracteres += len(novo_texto)
            
            # Processa palavras
            palavras = word_tokenize(novo_texto)
            self.palavras += len(palavras)
            
            for palavra in palavras:
                if palavra.strip():
                    self.palavras_unicas.add(palavra)
                    self.ultimas_palavras.append(palavra)
                    
                    # Atualiza maiores palavras
                    if not palavra in [p[1] for p in self.maiores_palavras]:
                        self.maiores_palavras.append((len(palavra), palavra))
                        self.maiores_palavras.sort(reverse=True)
                        self.maiores_palavras = self.maiores_palavras[:10]
            
            # Atualiza mÃ©tricas calculadas
            tempo_total = max(0.001, time.time() - self.inicio)
            self.chars_por_segundo = self.caracteres / tempo_total
            self.palavras_por_segundo = self.palavras / tempo_total
            self.tokens_por_segundo = self.tokens_bert / tempo_total
            
            # Calcula mÃ©dias e ratios
            if self.palavras > 0:
                tamanhos = [len(p) for p in self.palavras_unicas]
                self.media_tamanho_palavras = sum(tamanhos) / len(tamanhos) if tamanhos else 0
                self.diversidade_lexica = len(self.palavras_unicas) / self.palavras
                
            if self.tokens_bert > 0:
                self.token_ratio = len(self.token_unicos) / self.tokens_bert
            
            # Atualiza mÃ©tricas do sistema
            self.atualizar_metricas_sistema()
            
            # Processamento BERT assÃ­ncrono
            await self.processar_tokens_bert(novo_texto)
            
        except Exception as e:
            console.print(f"[yellow]Erro ao atualizar estatÃ­sticas: {e}[/yellow]")

    async def processar_tokens_bert(self, texto: str):
        """Processa tokens BERT de forma sÃ­ncrona"""
        if not TOKEN_COUNTER or not self.bert_tokenizer:
            return
            
        try:
            tokens = self.bert_tokenizer.tokenize(texto)
            stats = {
                'num_tokens': len(tokens),
                'unique_tokens': len(set(tokens)),
                'subwords': sum(1 for t in tokens if t.startswith('##')),
                'special': sum(1 for t in tokens if t in self.bert_tokenizer.special_tokens_map.values()),
                'max_len': max(len(t) for t in tokens) if tokens else 0,
                'avg_len': np.mean([len(t) for t in tokens]) if tokens else 0
            }
            
            self.atualizar_estatisticas_bert(stats)
            
        except Exception as e:
            console.print(f"[yellow]Erro ao processar tokens BERT: {e}[/yellow]")

    def atualizar_estatisticas_bert(self, stats: Dict):
        """Atualiza estatÃ­sticas do BERT"""
        try:
            self.tokens_bert += stats['num_tokens']
            self.token_stats['media_len'] = stats['avg_len']
            self.token_stats['max_len'] = max(self.token_stats['max_len'], stats['max_len'])
            self.token_stats['subwords_ratio'] = stats['subwords'] / max(1, stats['num_tokens'])
            self.token_stats['special_tokens'] += stats['special']
            
            # Atualiza taxa de processamento
            tempo_total = max(0.001, time.time() - self.inicio)
            self.tokens_por_segundo = self.tokens_bert / tempo_total
            
        except Exception as e:
            console.print(f"[yellow]Erro ao atualizar estatÃ­sticas BERT: {e}[/yellow]")

    def calcular_metricas_avancadas(self, texto: str):
        try:
            if not texto.strip():
                return
                
            # TokenizaÃ§Ã£o segura
            if self.metrics.bert_tokenizer:
                tokens_bert = self.metrics.bert_tokenizer.tokenize(texto)
                self.tokens_bert = max(1, self.tokens_bert + len(tokens_bert))
            
            # AnÃ¡lise de sentenÃ§as
            sentences = nltk.sent_tokenize(texto)
            if sentences:
                self.sentences.extend(sentences)
            
            # Embeddings seguros
            if self.metrics.sentence_model and texto.strip():
                try:
                    embedding = self.metrics.sentence_model.encode(texto)
                    magnitude = float(np.linalg.norm(embedding))
                    
                    if not np.isnan(magnitude) and magnitude > 0:
                        self.metrics.embedding_magnitudes.append(magnitude)
                        
                        # Atualizar estatÃ­sticas
                        mags = [m for m in self.metrics.embedding_magnitudes if m > 0]
                        if mags:
                            self.embedding_stats['min_magnitude'] = min(mags)
                            self.embedding_stats['max_magnitude'] = max(mags)
                            self.embedding_stats['avg_magnitude'] = self.safe_mean(mags)
                except:
                    pass
            
            # MÃ©tricas de sistema
            try:
                self.metrics.cpu_usage = psutil.cpu_percent()
                self.metrics.memory_usage = psutil.virtual_memory().percent
                if len(GPUtil.getGPUs()) > 0:
                    self.metrics.gpu_usage = GPUtil.getGPUs()[0].load * 100
            except:
                pass
                
        except Exception as e:
            console.print(f"[yellow]Aviso em mÃ©tricas avanÃ§adas: {str(e)}[/yellow]")

    def atualizar_metricas_sistema(self):
        """Atualiza mÃ©tricas do sistema"""
        try:
            self.cpu_total = psutil.cpu_percent()
            self.cpu_cores = psutil.cpu_percent(percpu=True)
            self.ram = psutil.virtual_memory()
            self.disk = psutil.disk_usage('/')
        except Exception as e:
            console.print(f"[yellow]Erro ao atualizar mÃ©tricas do sistema: {e}[/yellow]")

    def formatar_tempo(self, segundos):
        """Formata segundos em HH:MM:SS"""
        horas = int(segundos // 3600)
        minutos = int((segundos % 3600) // 60)
        segs = int(segundos % 60)
        return f"{horas:02d}:{minutos:02d}:{segs:02d}"

    def criar_grid_layout(self):
        try:
            tempo_atual = time.time()
            tempo_total = max(0.001, tempo_atual - self.inicio)
            tempo_formatado = str(timedelta(seconds=int(tempo_total)))

            layout = Layout()
            layout.split_column(
                Layout(name="header", size=3),
                Layout(name="main", size=30),
                Layout(name="footer", size=3)
            )

            # Header com mÃ©tricas de processamento
            header = Panel(
                Align.center(
                    Text.assemble(
                        (f"ğŸš€ BERT Processor ", "bold cyan"),
                        (f"| â±ï¸ {tempo_formatado}", "magenta")
                    )
                ),
                border_style="blue",
                box=ROUNDED
            )
            layout["header"].update(header)

            # 6 colunas para mÃ©tricas
            layout["main"].split_row(
                Layout(name="system", ratio=1),
                Layout(name="process", ratio=1),
                Layout(name="tokens", ratio=1),
                Layout(name="words", ratio=1),
                Layout(name="stats", ratio=1),
                Layout(name="tops", ratio=1)
            )

            # 1. Sistema e Recursos
            system_stats = self.system_monitor.get_cpu_stats()
            memory_stats = self.system_monitor.get_memory_stats()
            
            system_table = Table(box=ROUNDED, expand=True)
            system_table.add_column("ğŸ’» Sistema", style="cyan")
            system_table.add_column("Valor", justify="right", style="green")
            
            # CPU com fallback
            system_table.add_row("ğŸ–¥ï¸ CPU Total", f"{system_stats['total']:.1f}%")
            for i, cpu in enumerate(system_stats['cores']):
                with suppress(Exception):
                    system_table.add_row(f"Core {i+1}", f"{cpu:.1f}%")
            
            # MemÃ³ria com fallback
            system_table.add_row("ğŸ§  RAM Uso", f"{memory_stats['percent']}%")
            system_table.add_row("ğŸ’¾ RAM Total", f"{memory_stats['total']/1024**3:.1f}GB")
            system_table.add_row("ğŸ“Š RAM Livre", f"{(memory_stats['total']-memory_stats['used'])/1024**3:.1f}GB")
            
            if memory_stats['swap_percent'] > 0:
                system_table.add_row("ğŸ’« Swap", f"{memory_stats['swap_percent']}%")
            
            # InformaÃ§Ãµes do sistema
            system_table.add_row("ğŸ”§ Sistema", platform.system())
            system_table.add_row("ğŸ“Œ Python", platform.python_version())
            
            if self.system_monitor.fallback_mode:
                system_table.add_row("âš ï¸ Modo", "Fallback", style="yellow")
            
            layout["system"].update(Panel(
                system_table,
                title="ğŸ’» Sistema" + (" (Fallback)" if self.system_monitor.fallback_mode else ""),
                border_style="blue"
            ))

            # 2. Processamento
            process_table = Table(box=ROUNDED, expand=True)
            process_table.add_column("âš¡ Processo", style="magenta")
            process_table.add_column("Valor", justify="right", style="yellow")
            
            process_table.add_row("ğŸ“ IteraÃ§Ã£o", f"{self.iteracao_atual}/{self.total_iteracoes}")
            process_table.add_row("â±ï¸ Tempo", tempo_formatado)
            process_table.add_row("ğŸ“Š Chars/s", f"{self.chars_por_segundo:.1f}")
            process_table.add_row("ğŸš€ Words/s", f"{self.palavras_por_segundo:.1f}")
            process_table.add_row("ğŸ’¾ Buffer", f"{len(self.buffer):,}")
            process_table.add_row("ğŸ“ˆ Total KB", f"{self.caracteres/1024:.1f}")
            
            layout["process"].update(Panel(process_table, title="âš¡ Processamento", border_style="magenta"))

            # 3. Tokens BERT
            tokens_table = Table(box=ROUNDED, expand=True)
            tokens_table.add_column("ğŸ¯ Tokens", style="blue")
            tokens_table.add_column("Valor", justify="right", style="cyan")
            
            tokens_table.add_row("ğŸ“Š Total", f"{self.tokens_bert:,}")
            tokens_table.add_row("ğŸ”„ Por Seg", f"{self.tokens_por_segundo:.1f}")
            tokens_table.add_row("ğŸ“ˆ Ãšnicos", f"{len(self.token_unicos):,}")
            tokens_table.add_row("ğŸ¯ Ratio", f"{self.token_stats['subwords_ratio']:.1%}")
            tokens_table.add_row("ğŸ“ MÃ©dia Len", f"{self.token_stats['media_len']:.1f}")
            tokens_table.add_row("âš¡ Especiais", f"{self.token_stats['special_tokens']}")
            
            # Top 5 tokens mais frequentes
            tokens_table.add_row("ğŸ“ˆ TOP TOKENS", "", style="bold magenta")
            for token, freq in self.top_tokens[:5]:
                tokens_table.add_row("ğŸ”¤", f"{token} ({freq})")
            
            layout["tokens"].update(Panel(tokens_table, title="ğŸ¯ Tokens BERT", border_style="cyan"))

            # 4. AnÃ¡lise de Palavras
            words_table = Table(box=ROUNDED, expand=True)
            words_table.add_column("ğŸ“ Palavras", style="yellow")
            words_table.add_column("Valor", justify="right", style="green")
            
            words_table.add_row("ğŸ“š Total", f"{self.palavras:,}")
            words_table.add_row("ğŸ¯ Ãšnicas", f"{len(self.palavras_unicas):,}")
            words_table.add_row("ğŸ“Š MÃ©dia Len", f"{self.media_tamanho_palavras:.1f}")
            words_table.add_row("ğŸ’« Diversidade", f"{self.diversidade_lexica:.1%}")
            
            # Ãšltimas 10 palavras
            words_table.add_row("ï¿½ï¿½ï¿½ ÃšLTIMAS", "", style="bold cyan")
            for palavra in list(self.ultimas_palavras)[-10:]:
                words_table.add_row("ğŸ“–", palavra)
            
            layout["words"].update(Panel(words_table, title="ğŸ“ AnÃ¡lise", border_style="yellow"))

            # 5. EstatÃ­sticas
            stats_table = Table(box=ROUNDED, expand=True)
            stats_table.add_column("ğŸ“Š Stats", style="red")
            stats_table.add_column("Valor", justify="right", style="blue")
            
            stats_table.add_row("ğŸ¯ EficiÃªncia", f"{self.eficiencia_tokens:.1%}")
            stats_table.add_row("ğŸ“ˆ Cobertura", f"{self.cobertura_vocab:.1%}")
            stats_table.add_row("ğŸ’« Densidade", f"{self.densidade_texto:.2f}")
            stats_table.add_row("âš¡ Performance", f"{self.performance_score:.1f}")
            
            layout["stats"].update(Panel(stats_table, title="ğŸ“Š EstatÃ­sticas", border_style="red"))

            # 6. Tops e Rankings
            tops_table = Table(box=ROUNDED, expand=True)
            tops_table.add_column("ğŸ† Tops", style="green")
            tops_table.add_column("Valor", justify="right", style="magenta")
            
            # Top 10 maiores palavras
            tops_table.add_row("ğŸ“ MAIORES", "", style="bold yellow")
            for tamanho, palavra in sorted(self.maiores_palavras, reverse=True)[:10]:
                tops_table.add_row("ğŸ“", f"{palavra} ({tamanho})")
            
            layout["tops"].update(Panel(tops_table, title="ğŸ† Rankings", border_style="green"))

            return layout

        except Exception as e:
            console.print(f"[yellow]Aviso no layout: {str(e)}[/yellow]")
            return Layout()

class StreamProcessor:
    def __init__(self):
        self.console = Console()
        self.stats = StreamStats()
        self.live = Live(
            self.stats.criar_grid_layout(),
            console=self.console,
            auto_refresh=True,
            refresh_per_second=10,
            screen=True
        )

    async def processar_yaml(self, prompt: str, arquivo_yaml: Path, iteracao: int, total: int):
        """Processa um Ãºnico YAML com atualizaÃ§Ãµes em tempo real"""
        try:
            self.stats.iteracao_atual = iteracao
            self.stats.total_iteracoes = total
            
            # Inicializa o modelo
            model = genai.GenerativeModel(
                model_name=NOME_MODELO,
                generation_config=CONFIG_GERACAO
            )

            # Processa o stream
            response = model.generate_content(prompt, stream=True)
            
            # Abre o arquivo em modo append para escrita em tempo real
            async with aiofiles.open(arquivo_yaml, 'a', encoding='utf-8') as f:
                buffer = ""
                for chunk in response:
                    if chunk.text:
                        texto = chunk.text
                        buffer += texto
                        
                        # Escreve imediatamente no arquivo
                        await f.write(texto)
                        await f.flush()  # ForÃ§a a escrita no disco
                        
                        # Atualiza estatÃ­sticas
                        await self.stats.atualizar(texto, iteracao, arquivo_yaml.name)
                        
                        # Atualiza display em tempo real
                        self.live.update(self.stats.criar_grid_layout())
                        
                        # Pequena pausa para nÃ£o sobrecarregar o display
                        await asyncio.sleep(0.01)
                
                # Processa mÃ©tricas finais do texto completo
                self.stats.calcular_metricas_avancadas(buffer)
                self.live.update(self.stats.criar_grid_layout())
            
            return True

        except Exception as e:
            self.console.print(f"[red]Erro ao processar YAML {iteracao}: {str(e)}[/red]")
            return False

    async def processar_iteracoes(self, palavra_inicial: str):
        """Processa todas as iteraÃ§Ãµes sequencialmente"""
        total_iteracoes = 20
        
        with self.live:
            self.console.clear()
            
            for i in range(total_iteracoes):
                try:
                    # Prepara diretÃ³rio e arquivo
                    output_dir = Path("generated-yaml-text-to-embedding")
                    output_dir.mkdir(exist_ok=True)
                    
                    # Gera nome Ãºnico para o arquivo
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    hash_id = hashlib.md5(f"{timestamp}_{i}".encode()).hexdigest()[:8]
                    arquivo_yaml = output_dir / f"embedding_stream_v1_{hash_id}.yaml"
                    
                    # Template do prompt
                    prompt = f"""
                    Baseado na palavra-chave '{palavra_inicial}', gere um YAML tÃ©cnico e detalhado.
                    IteraÃ§Ã£o: {i+1}/{total_iteracoes}
                    
                    Requisitos:
                    - Estrutura YAML vÃ¡lida
                    - ConteÃºdo tÃ©cnico relacionado Ã  palavra-chave
                    - MÃ­nimo de 3 nÃ­veis de profundidade
                    - Incluir exemplos prÃ¡ticos
                    """
                    
                    # Processa um YAML por vez
                    console.print(f"\n[cyan]Processando YAML {i+1}/{total_iteracoes}...[/cyan]")
                    await self.processar_yaml(prompt, arquivo_yaml, i+1, total_iteracoes)
                    
                    # Pequena pausa entre arquivos
                    await asyncio.sleep(1)
                    
                except Exception as e:
                    self.console.print(f"[red]Erro na iteraÃ§Ã£o {i+1}: {str(e)}[/red]")

async def main():
    try:
        processor = StreamProcessor()
        
        console.print(f"\n{EMOJI['palavra']} [cyan]Digite a palavra inicial:[/cyan]")
        palavra_inicial = input().strip()
        
        if not palavra_inicial:
            console.print("[red]Palavra inicial nÃ£o pode estar vazia![/red]")
            return
        
        console.clear()
        await processor.processar_iteracoes(palavra_inicial)
        
        console.print(Panel(
            f"[green]ğŸ‰ Processo completo![/green]\n"
            f"YAMLs gerados com sucesso na pasta 'generated-yaml-text-to-embedding'",
            border_style="green"
        ))
        
    except KeyboardInterrupt:
        console.print("\n[yellow]OperaÃ§Ã£o cancelada pelo usuÃ¡rio.[/yellow]")
    except Exception as e:
        console.print(f"[red]Erro durante o processamento: {str(e)}[/red]")

if __name__ == "__main__":
    asyncio.run(main())

# ----ATHENA----
